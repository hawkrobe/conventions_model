---
title: "Basic-level emergence"
output:
  pdf_document: default
  html_notebook: default
  html_document: 
    smart: false
    
---

# Import libraries

```{r results="hide"}
library(tidyverse)
library(ggthemes)
library(lme4)
library(lmerTest)

pal = colorblind_pal()(3)
condition_pal = c(pal[1], pal[3], pal[2])
```

# Import data  

Import trajectories of clicks & drops.
Pull in condition information & map words to distinct identifiers. 

```{r results="hide"}
raw_clicks = read_delim('../data/experiment2/allClicks.csv', '\t')
raw_drops = read_delim('../data/experiment2/allDrops.csv', '\t')
masterWordIDLookup <- read_delim('../data/experiment2/allWordPostTest.csv', '\t') %>%
  group_by(gameid) %>%
  mutate(wordID = paste0('word', as.numeric(factor(target)))) %>%
  rename(text = target) %>%
  select(gameid, text, wordID) %>%
  distinct()
masterGameIDLookup <- raw_clicks %>%
  mutate(id = paste0('game', as.numeric(factor(gameid)))) %>%
  select(gameid, id, condition) %>%
  distinct()
```

Read in post-test results

```{r}
postTest_word = read_delim('../data/experiment2/allWordPostTest.csv', '\t') %>%
  gather(object, meaning, blueSquare1:stripedCircle2) %>%
  mutate(blue = grepl('blue', object),
         red = grepl('red', object),
         striped = grepl('striped', object),
         spotted = grepl('spotted', object),
         circle = grepl("Circle", object),
         square = grepl("Square", object)) %>%
  right_join(d) %>%
  select(iterationName:square, condition) %>%
  group_by_at(vars(-condition)) %>%
  summarize(condition = first(condition)) %>%
  rename(text = target) %>%
  left_join(masterWordIDLookup) %>%
  left_join(masterGameIDLookup) 
length(unique(postTest_word$gameid))
```

Need to read in objects individually because headers are all unique

```{r results="hide"}
file_list <- list.files('../data/experiment2/postTest_object/')
postTest_obj = data.frame()
for(file in file_list) {
  result <- read_delim(file = paste0('../data/experiment2/postTest_object/', file), delim = '\t') %>%
    gather(word, meaning, -iterationName, -gameid, -time, -target, -finalRole, -eventType)
  postTest_obj = rbind(postTest_obj, result)
}
```

Combine post-tests; take intersection of meanings as the best estimate of true meaning (more conservative)

```{r}
postTest <- postTest_obj %>% 
  rename(object = target, text = word, objectToWordMeaning = meaning) %>%
  left_join(masterWordIDLookup) %>%
  inner_join(postTest_word %>% rename(wordToObjectMeaning = meaning), 
             by = c('gameid', 'object', 'finalRole', 'wordID')) %>%
  select(-ends_with('.x'), -ends_with('.y')) %>%
  mutate(internalConsistency = objectToWordMeaning == wordToObjectMeaning) %>%
  mutate(meaning = objectToWordMeaning & wordToObjectMeaning) %>%
  mutate(condition = case_when(condition == 'subOnly' ~ 'fine',
                               condition == 'mixedLower' ~ 'mixed',
                               TRUE ~ 'coarse'),
         condition = fct_relevel(condition, 'coarse', 'mixed', 'fine'))
```

Filter out incompletes & compute cumulative accuracy. We also divide into quarters to compare games that ran different amounts of trials.

```{r}
incompletes <- raw_clicks %>% 
  group_by(gameid, condition) %>%
  tally() %>%
  filter(n < 90) %>%
  pull(gameid)

d <- raw_clicks %>%
  mutate(acc = ifelse(correct, 1, 0)) %>%
  filter(!(gameid %in% incompletes)) %>%
  group_by(gameid) %>%
  mutate(quarter = floor((trialNum - 1) / (last(trialNum)/4))) %>%
  mutate(cumAcc = cumsum(acc)) %>%
  mutate(overallAcc = last(cumAcc)/last(trialNum)) %>%
  left_join(raw_drops, by = c('gameid', 'trialNum', 'intendedName')) %>%
  select(-ends_with('y'), -ends_with('x'), -correct) %>%
  left_join(masterWordIDLookup) %>%
  left_join(masterGameIDLookup) %>%
  ungroup()
```
Look at how many games we have in each condition

```{r}
d %>% 
  group_by(gameid, condition) %>%
  tally() %>%
  group_by(condition) %>%
  summarize(n = length(n))
```
Write out in nice format for BDA.

```{r}
gameIDs = d %>% 
  pull(id) %>%
  unique()

for(i in gameIDs) {
  toWrite = d %>% 
    ungroup() %>%
    filter(id == i) %>%
    mutate(speakerID = ifelse(trialNum %% 2 == 0, 1, 2),
           listenerID = ifelse(trialNum %% 2 == 0, 2, 1)) %>%
    select(-gameid, -text, -acc, -quarter, -cumAcc, -overallAcc, -timeFromRoundStart)  
  write_csv(toWrite, path = paste0('../simulations/cogsci2018/input/', i, '.csv'))
}

d %>%
  select(id, condition) %>%
  unique() %>%
  write_csv( path = '../simulations/cogsci2018/input/all_gameids.csv')
```

# Behavioral Results 

## Partners successfully learn to communicate (Fig. 8)

What is the intercept?

```{r}
t.test((d %>% ungroup() %>% filter(trialNum == 1))$acc, mu = 0.25)
```

Make Fig. 8

```{r}
d %>%
  mutate(sextet = floor((trialNum - 1) / 16)) %>%
  group_by(condition, sextet) %>%
  tidyboot_mean(acc) %>%
  ggplot(aes(x = sextet, y = 100 * empirical_stat, color = condition)) +
    #geom_point(alpha = 0.2, stroke = 0, size = 2) +
    geom_line()+
    theme_few() +
    geom_errorbar(aes(ymin = ci_lower*100, ymax = ci_upper*100), width = 0) +
    geom_hline(yintercept = 25, lty = 'dashed') +
    #geom_smooth(method = 'loess') +
    scale_color_manual(values = condition_pal) +
    theme(aspect.ratio = 1) +
    labs(x = 'trial #', y = '% correct') +
    ylim(0, 100)

ggsave('../writing/journal_manuscript/figures/Exp2_empirical_accuracy.pdf', width = 5, height = 4, 
       useDingbats=FALSE)
```

The overall increase is significant...and adding condition improves model fit.

```{r}
trialOnly <- d %>%
  glmer(acc ~ trialNum + (1 + trialNum | gameid), 
        family = 'binomial', data = .)
trialAndCondition <- d %>%
  glmer(acc ~ trialNum + condition + (1 + trialNum | gameid), 
        family = 'binomial', data = .)

trialOnly %>% summary()
anova(trialOnly, trialAndCondition)
```


# Validating post-test lexicons

```{r}
cat('have post-test measures for', 
    length(unique(paste0(postTest$gameid, postTest$finalRole))),
    'participants')

postTest %>%
  group_by(gameid, finalRole) %>%
  summarize(numMismatch = 128-sum(internalConsistency)) %>% 
  ungroup() %>%
  summarize(medianMismatches = median(numMismatch),
            meanMismatches = mean(numMismatch),
            totalPossible = 128)
```

# Contextual pressures shape the lexicon

```{r}
d %>%
  mutate(repNum = floor((trialNum - 1) / 8)) %>%
  mutate(sextet = floor((trialNum - 1) / 16)) %>%
  group_by(gameid, condition, sextet) %>%
  mutate(numUniqueWordsUsed = length(unique(wordID))) %>%
  group_by(condition, sextet) %>%
  tidyboot::tidyboot_mean(numUniqueWordsUsed, nboot= 100) %>%
  ggplot(aes(x = sextet, y = empirical_stat, color = condition)) +
    geom_line() +
    geom_hline(yintercept = c(4, 8), linetype = 'dashed') +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width=0) +
    theme_few() +
    scale_color_manual(values = condition_pal) +
    theme(aspect.ratio = 1) +
    labs(y = "number unique words used")

ggsave('../writing/journal_manuscript/figures/Exp2_empirical_numwords.pdf', width = 5, height = 4, useDingbats = F)
```
Statistics

```{r}
uniqueWords <- d %>%
  mutate(sextet = floor((trialNum - 1) / 16)) %>%
  group_by(gameid, condition, sextet) %>%
  summarize(numUniqueWordsUsed = length(unique(wordID))) %>%
  mutate(centeredRep = scale(sextet, scale=T))

uniqueWords %>%
  lmer(numUniqueWordsUsed ~ centeredRep * condition + (1 + centeredRep | gameid),
       data = .) %>%
  summary()
```

Compare raw vocabulary size in post-test

```{r}
postTest %>%
  group_by(gameid, finalRole, wordID, condition) %>%
  summarize(numObjects = sum(meaning)) %>%
  filter(numObjects > 0) %>%
  group_by(gameid, finalRole, condition) %>%
  summarize(vocabSize = n()) %>%
  lmer(vocabSize ~ condition + (1 | gameid), data = .) %>%
  summary()
```

Compare average extension size in post-test

```{r}
postTest %>%
  group_by(gameid, finalRole, wordID, condition) %>%
  summarize(extensionSize = sum(meaning)) %>%
  filter(extensionSize > 0) %>%
  lmer(extensionSize ~ condition + (1 | gameid), data = .) %>%
  summary()
```

How many abstract vs. specific terms?

```{r}
lexiconCounts <- postTest %>% 
  group_by(gameid, finalRole, wordID, condition) %>%
  summarize(numMeanings = sum(meaning)) %>%
  group_by(condition, numMeanings) %>%
  tally() %>%
  group_by(condition) %>%
  mutate(pct = n / sum(n)) %>%
  filter(numMeanings < 3) %>%
  ungroup() 

lexiconCounts %>%
  mutate(numWords = 16*pct) %>%
ggplot(aes(x = condition, y = numWords, fill = fct_relevel(factor(numMeanings), '0', '2', '1'))) +
    geom_bar(stat = 'identity', width=.75) +
    scale_fill_manual(values = c('#E6E6E5','#97A5A4', '#231F20')) +
    scale_y_continuous(breaks = c(0,4,8,12,16)) +
    theme_few() +
    labs(x = "", y = '# words with post-test meaning') +
    theme(aspect.ratio = 2)
ggsave('../writing/cogsci18/figures/lexiconContent.pdf', width = 3, height = 3)
```

What is modal response in each condition?

```{r}
postTest %>% 
  group_by(gameid, finalRole, wordID) %>%
  filter(meaning == 1) %>%
  summarize(subordinate = sum(meaning) == 1,
            basic = (sum(meaning) == 2 & 
                       (all(red) | all(blue) | all(striped) | all(spotted)))) %>%
  group_by(gameid, finalRole) %>%
  summarize(numSub = sum(subordinate),
            numBasic = sum(basic)) %>%
  left_join(d) %>%
  group_by(gameid, finalRole, condition) %>%
  summarize(numSub = mean(numSub), numBasic=mean(numBasic)) %>%
  group_by(condition, numSub, numBasic) %>%
  tally() %>%
  group_by(condition) %>%
  mutate(pct = n/sum(n)) %>%
  select(-n) %>%
  filter(pct == max(pct))
```

# Additional exploratory analyses

## Vizualize response times

```{r}
d %>% 
  group_by(trialNum, condition) %>%
  summarize(RT = mean(timeFromRoundStart)) %>%
  ggplot(aes(x = trialNum, y = RT/1000, color = condition)) +
    geom_point(alpha = 0.2) +
    theme_few() + 
    guides(color = FALSE) +
    scale_color_colorblind() +
    geom_smooth(method = 'loess', span = 0.4) +
    ylim(0, NA) +
    ylab("reaction time (seconds)")
```

## Overall accuracy over time

```{r}
d %>% 
  group_by(trialNum) %>%
  summarize(percentCorrect = mean(acc)) %>%
  ggplot(aes(x = trialNum, y = percentCorrect)) +
    geom_point() +
    theme_few() + 
    geom_hline(yintercept = 0.25, linetype = 2) +
    guides(color = FALSE) +
    geom_smooth(method = 'loess') +
    ylab("accuracy") +
    ylim(0,1) 

ggsave('~/Downloads/singleLine.pdf', height = 4, width = 6)
```

### *Individual* cumulative accuracy curves over time

Here we see very clearly the different pairs separate out (some never converge)

```{r}
ggplot(d, aes(x = trialNum, y = cumAcc, group = gameid)) +
  geom_line() +
  theme_few() + 
  guides(color = FALSE) +
  ylab("cumulative accuracy")
```

### Accuracy distributions by quartile of game

So we can clearly see the distributions... 

```{r}
d %>% 
  group_by(gameid, condition, quarter) %>%
  summarize(percentCorrect = mean(acc)) %>%
  ggplot(aes(x = percentCorrect, fill = condition)) +
    geom_histogram(bins = 12) +
    geom_vline(xintercept = 0.75) +
    geom_vline(xintercept = 0.25, linetype = 'dotted') +
    theme_few() + 
    guides(fill = FALSE) +
    xlim(-0.1,1.1) +
    scale_x_continuous(breaks = c(0,.25,.5,.75,1)) +
    scale_fill_manual(values = condition_pal) +
    facet_grid(condition ~ quarter, scales = 'free_y') 

ggsave('../writing/journal_manuscript/figures/exp2-acc-grid.pdf', units = 'in', width = 8, height = 6)
```

We see a slightly bimodal distribution where some people never converge.


### Response times also go down

```{r}
d %>% 
  ungroup() %>% 
  mutate(timeFromRoundStart = log(timeFromRoundStart/1000), 
         trialNum = scale(trialNum, center=F,scale= T)) %>%
  lmer(timeFromRoundStart ~ trialNum + (1 + trialNum| gameid),  
               data = .) %>%
    summary()
```

### How many pairs didn't 'fully converge' in each condition

```{r}
accuracies <- d %>% 
  filter(quarter == 3) %>%
  group_by(gameid, condition) %>%
  summarize(percentCorrect = mean(acc))

accuracies %>% 
  group_by(condition) %>% 
  mutate(nGames = length(gameid)) %>% 
  filter(percentCorrect < 0.75) %>% 
  summarize(n = n(), pctGames = n / mean(nGames))
```

## internal consistency (mismatches)

```{r}
postTest %>%
  group_by(gameid, finalRole, condition) %>%
  summarize(pctConsistent = 128- sum(internalConsistency)) %>%
  ggplot(aes(x = pctConsistent)) +
    geom_histogram(bins = 35) +
    theme_few() +
    facet_wrap(~ condition) +
    xlab('% of mismatches among post-test responses')

postTest %>%
  group_by(gameid, finalRole, condition) %>%
  summarize(pctConsistent = 128- sum(internalConsistency)) %>%
  group_by(condition) %>%
  summarize(m = mean(pctConsistent))
```


## Check differences in *cross-partner* mismatches across conditions

```{r}
mismatches <- postTest %>%
  select(-blue, -red, -striped, -spotted, -circle, -square, -internalConsistency) %>%
  gather(meaningType, value, meaning, objectToWordMeaning, wordToObjectMeaning) %>%
  spread(finalRole, value) %>%
  group_by(gameid, object, wordID, condition, meaningType) %>%
  summarize(match = listener == speaker) %>%
  group_by(gameid, condition, meaningType) %>%
  summarize(numMismatches = 128-sum(match))

ggplot(mismatches, aes(x = numMismatches)) +
    geom_histogram(binwidth = 1) +
    theme_few() +
    xlab('# mismatches') +
   facet_wrap(meaningType ~ condition)

mismatches %>% 
  group_by(condition) %>% 
  filter(meaningType == 'meaning') %>% 
  summarize(m = median(numMismatches, na.rm = T))

mismatches %>% 
  ungroup() %>% 
  filter(meaningType == 'meaning') %>%
  lm(numMismatches ~ condition, data = .) %>%
  summary()
```

Note that pairs that didn't technically align that well on the post-test could still perform pretty well if one partner simply has a stricter meaning than the other but the difference is never relevant. Still, no significant difference across conditions (though mixed vs. coarse is marginal).

```{r}
mismatches %>%
  filter(!(gameid %in% missingPostTests)) %>%
  ungroup() %>% 
  filter(meaningType == 'meaning') %>% 
  ggplot(aes(x = condition, y = numMismatches)) +
    geom_boxplot() +
    theme_few()

mismatches %>% 
  filter(!(gameid %in% missingPostTests)) %>%
  ungroup() %>%
  filter(meaningType == 'meaning') %>%
  lm(numMismatches ~ condition, data = .) %>%
  summary()
```

### Do pairs with more similar lexica perform better?

```{r}
mismatchVsAcccc <- mismatches %>% 
  inner_join(d, by = c('gameid')) %>%
  group_by(gameid, condition.x) %>%
  summarize(acc = mean(overallAcc), numMismatches = mean(numMismatches)) %>%
  filter(!is.na(numMismatches))

ggplot(mismatchVsAcc, aes(x = acc, y = numMismatches, color = condition.x)) +
    geom_point() +
    geom_smooth(method = 'lm') +
    theme_few()

cor(mismatchVsAcc$numMismatches,mismatchVsAcc$acc, method = 'spearman')
```

## Post-test analyses

### Coverage of space?

Coverage in shared lexicon? This analysis pretty conservative, since it uses the 'intersection' metric of internal consistency: a word is only in a particular player's lexicon if they marked it in both directions, hence we're probably under-estimating their vocab. If we've underestimated both peoples' vocabs, we've also underestimated their overlap, which is probably dragging these down.

```{r}
coverageDF <- postTest %>%
  select(-blue, -red, -striped, -spotted, -circle, -square, -internalConsistency) %>%
  filter(!(gameid %in% missingPostTests)) %>%
  gather(meaningType, value, meaning, objectToWordMeaning, wordToObjectMeaning) %>%
  spread(finalRole, value) %>%
  group_by(gameid, object, wordID, condition, meaningType) %>%
  summarize(match = listener & speaker) %>%
  filter(meaningType == 'meaning') %>%
  group_by(gameid, object, condition) %>%
  summarize(numWord = sum(match)) %>%
  group_by(gameid, condition) %>%
  summarize(numObjectsWithSingleWord = sum(numWord == 1),
            numObjectsWithMultipleWords = sum(numWord > 1))

coverageDF %>%
  group_by(condition) %>% 
  summarize(median(numObjectsWithSingleWord)) 

coverageDF %>% 
  lm(numObjectsWithSingleWord ~ condition, data = .) %>%
  summary()
```

### Proportion of specific & abstract within single lexicon?

```{r}
pctDF <- postTest %>%
  group_by(gameid, finalRole, wordID, condition) %>%
  filter(meaning == 1) %>%
  summarize(specific = sum(meaning) == 1,
            abstract = sum(meaning) > 1)

pctDF %>%
  group_by(gameid, finalRole, condition) %>%
  summarize(numSpecific = sum(specific),
            numAbstract = sum(abstract)) %>%
  ggplot(aes(x = numSpecific+.5, y = numAbstract+.5)) +#, color = numSub > 0 & numBasic > 0)) +
    geom_bin2d(binwidth = c(1,1))  +
    facet_grid(~ condition) +
    theme_few() +
    xlab("# words referring to single object") +
    ylab("# words referring \n to multiple objects") +
    theme(aspect.ratio=.5, legend.position = 'top') +
    scale_y_continuous(breaks=c(.5, 1.5, 2.5, 3.5, 4.5, 5.5), labels = 0:5, limits = c(NA, 5.5)) +
    scale_x_continuous(breaks=c(0.5,2.5, 4.5, 6.5, 8.5, 10.5), labels = c(0,2,4,6,8,10), limits = c(NA,10.5)) +
    scale_fill_gradient(low = "grey90", high = "black") 
ggsave("../writing/journal_manuscript/figures/mixtureOfTerms.pdf", width = 8, height =3.5)
```

Test proportion of specific vs. abstract distribution within lexicon.
How many objects does each label correspond to (i.e. how many meanings at sub-level vs. basic-level)

```{r}
pctDF %>%
  group_by(gameid, finalRole, condition) %>%
  summarize(nSpecific = sum(specific),
            nAbstract = sum(abstract),
            pctSpecific = nSpecific/(nSpecific + nAbstract),
            pctAbstract = nAbstract/(nSpecific + nAbstract))

lmer(nAbstract ~ condition + (1 | gameid), data = pctDF) %>%
  summary()
```

### Any violations of contrast, or things that are described by more than one word?

Basically, only this team?

```{r}
'0888-836cf6dd-4836-4d3e-bc34-2ad06f1a5352'
```

