// run using, e.g.:
// webppl partnerspecificity.wppl --require ./refModule/ --require webppl-csv -- --gameNum 'game1'

var unconstrainedUtterances = ['word1', 'word2', 'word3', 'word4'];
var derivedUtterances = ['word1_word2', 'word1_word3','word1_word4',
                         'word2_word3','word2_word4','word3_word4'];
var utterances = unconstrainedUtterances.concat(derivedUtterances);
var objects = ['bluecircle', 'redsquare'];
var meanings = ['bluecircle', 'redsquare'];
var numMeanings = meanings.length;

var params = {
  speakerAlpha : argv.speakerAlpha,
  listenerAlpha: argv.listenerAlpha,
  discountFactor: argv.discountFactor,
  costWeight: argv.costWeight,  
  guessingEpsilon: argv.guessingEpsilon,
  numTrials: 14,
  partnerID: 1,
  context: objects,
  utterances: utterances,
  objects: objects,
  inferOptions: {method: 'enumerate'}
};

console.log(params);

var trajectoryFile = csv.open('./output/conjunction_trajectory_' + argv.gameNum + '.csv');
var posttestFile = csv.open('./output/conjunction_meaningTest_' + argv.gameNum + '.csv');
csv.writeLine('gameNum,speakerAlpha,listenerAlpha,discountFactor,costWeight,guessingEpsilon,trialNum,\
              speakerID,listenerID,intendedName,topSpeakerChoice,topListenerChoice,correct', trajectoryFile);
csv.writeLine('gameNum,speakerAlpha,listenerAlpha,discountFactor,costWeight,guessingEpsilon,trialNum,agentID,\
              word1_cost,word1_inform,word2_cost,word2_inform,word1word2_cost,word1word2_inform,word1_production,\
              word2_production,word1word2_production,word1_belief,word2_belief,word3_belief,word4_belief', posttestFile);


var lexicalPrior = function() {
  var lexicon = _.zipObject(unconstrainedUtterances, map(function(utt) {
    var bias = 0.05;
    var preferredMeaning = (utt == 'word1' || utt == 'word2' ? 'bluecircle' : 'redsquare');
    var ps = map(function(meaning) {return meaning == preferredMeaning ? 1/2 + bias : 1/2 - bias;}, meanings);
    return sample(Categorical({vs: meanings, ps: ps}));
  }, unconstrainedUtterances));
  return {1: lexicon};
};

var postTest = function(iterationNum, trial, posterior1, posterior2) {
  var word1Meaning = marginalize(posterior1, function(x) {return x['word1']});
  var word2Meaning = marginalize(posterior1, function(x) {return x['word2']});
  var word3Meaning = marginalize(posterior1, function(x) {return x['word3']});
  var word4Meaning = marginalize(posterior1, function(x) {return x['word4']});
  csv.writeLine([
    iterationNum, params.speakerAlpha, params.listenerAlpha, params.discountFactor, params.costWeight, params.guessingEpsilon,
    trial.trialNum, trial.speakerID,
    params.costWeight * getUttCost('word1'),
    params.speakerAlpha * expectation(posterior1, function(lexicon) {
      var config = extend(params, {lexicon: lexicon});
      return L0('word1', config).score('bluecircle');
    }),
    params.costWeight * getUttCost('word2'),
    params.speakerAlpha * expectation(posterior1, function(lexicon) {
      var config = extend(params, {lexicon: lexicon});
      return L1('word2', config).score('bluecircle');
    }),
    params.costWeight * getUttCost('word1_word2'),      
    params.speakerAlpha * expectation(posterior1, function(lexicon) {
      var config = extend(params, {lexicon: lexicon});
      return L1('word1_word2', config).score('bluecircle');
    }),
    S('bluecircle', posterior1,params).score('word1'),
    S('bluecircle', posterior1,params).score('word2'),
    S('bluecircle', posterior1,params).score('word1_word2'),        
    word1Meaning.score('bluecircle'),
    word2Meaning.score('bluecircle'),
    word3Meaning.score('bluecircle'),
    word4Meaning.score('bluecircle')
  ].join(','), posttestFile);
};

// for each point in data, we want the model's predictions 
var iterate = function(iterationNum, dataSoFar) {
  var trialNum = dataSoFar[1].length;
  var currTrial = {
    intendedName: uniformDraw(objects),
    context : objects,
    trialNum: trialNum,
    repNum: Math.floor(trialNum / 2),
    partnerID: 1,
    speakerID: (trialNum % 2) == 0 ? 1 : 2,
    listenerID: (trialNum % 2) == 0 ? 2 : 1
  };

  var speakerPosterior = updatePosterior(dataSoFar[currTrial.speakerID], lexicalPrior, params);
  var listenerPosterior = updatePosterior(dataSoFar[currTrial.listenerID], lexicalPrior, params);

  // get marginal prediction of next data point over lexicon posterior
  var speakerOutput = S(currTrial.intendedName, speakerPosterior, params);
  var topSpeakerChoice =  sample(speakerOutput);
  var listenerOutput = L(topSpeakerChoice, listenerPosterior, params);
  var topListenerChoice = sample(listenerOutput);

  csv.writeLine([iterationNum, params.speakerAlpha, params.listenerAlpha, params.discountFactor, params.costWeight,
                 params.guessingEpsilon, currTrial.trialNum, currTrial.speakerID, currTrial.listenerID,
                 currTrial.intendedName, topSpeakerChoice, topListenerChoice,
                 topListenerChoice == currTrial.intendedName
                ].join(','), trajectoryFile);

  var newDataSoFar = _.zipObject([currTrial.speakerID, currTrial.listenerID], map(function(id) {
    return dataSoFar[id].concat(extend(currTrial, {
      role : id == currTrial.speakerID ? 'speaker' : 'listener',
      wordID : topSpeakerChoice,
      clickedName : topListenerChoice
    }));
  }, [currTrial.speakerID, currTrial.listenerID]));

  if(currTrial.trialNum < params.numTrials) {
    iterate(iterationNum, newDataSoFar);
  } 
};

map(function(i) {
  console.log('iteration', i)
  iterate(i, {1: [], 2: []});
}, _.range(50));
csv.close(trajectoryFile);
csv.close(posttestFile);
