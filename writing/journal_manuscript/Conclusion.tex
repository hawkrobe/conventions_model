Communication in a variable and non-stationary landscape of meaning creates unique computational challenges.
To address these challenges, we advanced a hierarchical Bayesian approach  in which agents continually adapt their beliefs about the form-meaning mapping used by each partner, in turn.
We formalized this approach by integrating three core cognitive capacities in a probabilistic framework: representing initial uncertainty about what a partner thinks words mean \textbf{(C1)}, partner-specific adaptation based on observations of language use in context \textbf{(C2)}, and hierarchical structure for graded generalization to new partners \textbf{(C3)}.
This unified model resolves several puzzles that have posed challenges for prior models of coordination and convention formation: why referring expressions shorten over repeated interactions with the same partner \textbf{(P1)}, how partner-specific common ground coexists with the emergence of conventions at the population level \textbf{(P2)}, and how context shapes which conventions emerge \textbf{(P3)}.

We conclude by raising five broader questions that arise from the proposed Adaptive Pragmatic Language User perspective, each suggesting pathways for future work: (1) in what ways is \emph{ad hoc} convention formation in adults the same as word learning in children and how does it differ? (2) to what extent do the proposed mechanisms depend on the communication modality? 
\adele{I'd maybe drop (3) from here, because the game is such a special case; (4) is also very hard to answer. Also, (5) is really central and eliminating (3) and (4) would bump it up)}
(3) what kinds of feedback are used to coordinate conventions in the reference game? (4) what kinds of social structure are reflected in the hierarchical prior, and (5) which representations are involved in adaptation at a process-level?

\subsection{Continuity of language learning across development}

There is a close mathematical relationship between our model of convention formation and recent probabilistic models of word learning in developmental science \cite<e.g.>{XuTenenbaum07_WordLearningBayesian,FrankGoodmanTenenbaum09_Wurwur}. 
This similarity suggests that the continual-learning mechanisms adults use to rapidly coordinate partner-specific conventions may be the same as those supporting lexical acquisition in children, although children's priors are weaker.
Adults do not stop learning new terms and new ways of using familiar terms, because  new contexts continually arise. Adults develop stronger and better-calibrated beliefs about their community's conventions over time and the range of available conventions extends to  a broader swath of communicative scenarios than those available to children.
In this section, we discuss three possible implications of viewing language development in terms of social coordination and convention.

First, common paradigms that test how well labels are understood typically focus on variability across referential contexts rather than variability across speakers  \cite{siskind1996computational,regier2005emergence,smith2014unrealized,yurovsky2015integrative}. 
Yet it is increasingly apparent that children are able to track \emph{who} produced the words they are learning and use this information to determine  how word meanings should generalize not just to other contexts but also to other speakers.
Bilingual children learn to expect different languages to be used by different speakers.
Even infants are sensitive to coarse social distinctions based on foreign vs. native language \cite{KinzlerDupouxSpelke07_LanguageGroups}, or accent \cite{KinzlerEtAl09_AccentRace}. Children are also sensitive to the reliability of individual speakers. For example, young children may limit the generalizability of observations from speakers who use language in idiosyncratic ways, such as a speaker who calls a ball a ``dog'' \cite{koenig2010sensitivity,luchkina2018eighteen}, and may even retrospectively update beliefs about earlier words after observing such idiosyncracies \cite{dautriche2021}. This discounting of idiosyncratic speakers may be understood as an instance of the same inductive problem that convention formation poses for adults in \textbf{P2}.
Unlike complete-pooling models, which predict that all observations should be equally informative about a community's conventions, our hierarchical model predicts that children should be able to explain away ``outliers'' without their community-level expectations being disrupted.
Indeed, a novel prediction generated by our account is that children should be able to accommodate idiosyncratic language \emph{within} extended interaction with the same speaker (e.g. continue to pretend the ball is called ``dog,'' given partner-specific common ground) while also limiting generalization of that convention \emph{across} other speakers.

Second, we have emphasized the importance of representing lexical \emph{uncertainty}, capturing expected variability in the population beyond the point estimates assumed by traditional lexical representations. 
But how do children calibrate their lexical uncertainty?
One possibility assigns a key role to the number of distinct speakers in a child's environment, by analogy to the literature on talker variability \cite{creel2011talker,clopper2004effects}.
Exposure to fewer partners may result in weaker \cite<e.g.>{lev2017talking} or mis-calibrated priors for meanings.
If an idiosyncratic construction is over-represented in the child's environment, they may later be surprised to find that it was specific to their household's lexicon and not shared by the broader community  \cite<see>[Chap. 6]{Clark09_FirstLanguageAcquisition}. 
Conversely, however, hierarchical inference predicts a blessing of abstraction \cite{GoodmanUllmanTenenbaum11_TheoryOfCausality}: under certain conditions, community-level conventions may be inferred even with relatively  sparse observations from each partner.
To resolve these questions, future work will need to develop new methods for eliciting children's expectations about partner-specificity and variability of meanings.

Third, our work suggests a new explanation for why young children struggle to coordinate \emph{ad hoc} conventions with one another in repeated reference games \cite{GlucksbergKraussWeisberg66_DevoRefGames,KraussGlucksberg69_DevoReferenceGames,KraussGlucksberg77_SocialNonsocialSpeech}. 
%When an experimenter feeds them messages produced by adult speakers in other games, they are able to maintain high accuracy even as the utterance reduce down to one- or two-word label. 
%When Kindergarteners play with one another, however, they continue to make errors even after 15 repetitions.
Children as old as fifth grade have been found to require assistance from an experimenter in order to successfully converge on new conventions in the repeated referential game used here  \cite{matthews2007toddlers}: instead of beginning with the long indefinite descriptions that adults provide, children began with shorter descriptions like \emph{Mother's dress} \cite<see also>{kempe2019adults}.
% \adele{I'm not sure what this shows; could simply be a failure to remember what had made them construe the tangram that way} While the failure to provide sufficient information was initially attributed to limits on the fifth graders' theory of mind, this explanation has been complicated by findings that 
%  children often cannot even interpret their own utterances after a delay \cite{asher1976children}.
Children's struggle to alight on utterances that can usefully discriminate one of the entities from the others may stem from a failure to anticipate how much information is required for the other person to discriminate the intended entity or from a failure to access the requisite complex formulations needed in the context of the experiment. Our model raises the possibility that the problem stems from the latter in that children's lexical priors are weaker: since there are no existing conventions for describing the novel objects in their vocabulary, their utterances are dispersed widely over easy-to-access ``good-enough'' formulations \cite{goldberg2019explain}.
Indeed, when children are paired with their caregivers rather than peers, they are successful at forming new conventions \cite{LeungEtAl20_Pacts}.
The adults helped to interactively scaffold the conventions, both by proactively seeking clarification in the listener role \cite<e.g.>{anderson1994interactive} and by providing more descriptive labels in the speaker role, which children adopted themselves on later trials.
These results highlight one way in which our model of convention formation may coincide with models of language acquisition in development: in both cases, listeners are trying to infer the meanings of the speaker's utterances \cite{bohn2019pervasive}. 



%The paragraph below could be omitted as an infinite number of questions are unanswered, and this has some new jargon. The final sentence above is a nice way to end this section.
%While we have highlighted three particular developmental phenomena where our approach may generate novel predictions, there are many finer-grained questions raised by our computational approach.
%For example, is the child's lexical expectations in communication best explained as a (resource-limited) representation of \emph{others'} lexicons, or as an egocentric (asocial) epistemic state? 
%To what extent is the ability to retrieve or use this lexical prior constrained by theory of mind development? 

\subsection{The role of communication modality}

%\begin{quote}
%The oral modality is not well suited to conveying messages mimetically (i.e., iconically), even though that function is also important to human languages. This function is, however, very well served by the manual modality. \cite[p.155]{}
%\end{quote}
%see Christiansen work for counterarguments (mostly within each language)

A core claim of our hierarchical account that the basic learning mechanisms underlying adaptation and convention formation are domain-general.
In other words, we predict that there is nothing inherently special about spoken or written language: any system that humans use to communicate should display similar \emph{ad hoc} learning and convention formation dynamics because in every case people are simply trying to infer the system of meaning being used by their partners. Directly comparing behavior in repeated reference games across different modalities is therefore necessary to determine which adaptation effects, if any, are robust and attributable to modality-general mechanisms.
In fact, there has been significant progress in understanding the dynamics of adaptation during communication in the  graphical modality \cite{GarrodFayLeeOberlanderMacLeod07_GraphicalSymbolSystems,TheisenEtAl10_SystematicityArbitrariness,hawkins2019disentangling}, the gestural modality \cite{FayListerEllisonGoldinMeadow13_GestureBeatsVocalization,motamedi2019evolving,bohn2019young} and other \emph{de novo} modalities \cite{Galantucci05_EmergenceOfCommunication,RobertsGalantucci12_DualityOfPatterning,RobertsEtAl15_IconocityOnCombinatoriality,VerhoefRobertsDingemanse15_Iconicity,VerhoefEtAl16_TemporalLanguage,kempe2019adults}.
\todo[]{Come up with a good name that includes Adaptive, Pragmatic, Hierarchical? PAH conventionalization model?}
The \textbf{PAH} model predicts a critical role for the \emph{priors} we build up across interactions with different individuals, and therefore predicts that different communication modalities should display certain systematic differences due to the representational structure of the communication channel.
For example, in the verbal modality, the tangram shapes from \citeA{ClarkWilkesGibbs86_ReferringCollaborative} are highly ``innominate'' %unusual and intricate instead? 
\cite{HupetEtAl91_CodabilityReference} -- most people do not have much experience naming or describing them with words, so relevant priors are weak and local adaptation plays a greater role.
In the graphical modality, where communication takes place by drawing on a shared sketchpad, people can be expected to have a stronger prior rooted in assumptions about shared perceptual systems and visual similarity \cite{fan2018common} -- drawing a quick sketch of the tangram's outline may suffice for understanding.

Other referents have precisely the opposite property: to distinguish between natural images of dogs, people may have strong existing conventions in the linguistic modality (e.g. `husky', `poodle', `pug') but making the necessarily fine-grained visual distinctions in the graphical modality may be initially very costly for novices \cite{fan2020pragmatic}, requiring the formation of local conventions to achieve understanding \cite{hawkins2019disentangling}. 
The gestural modality also has its own distinctive prior, which also allows communicators to use time and the space around them to convey mimetic or depictive meanings that may be difficult to encode verbally or graphically \cite{goldin-meadow_role_1999,clark2016depicting,mcneill1992hand}. 
We suggest that differences in production and comprehension across modalities may therefore be understood by coupling modality-specific priors with modality-generic learning mechanisms.


%If we adhered solely to the verbal modality, we would be limited to a fairly narrow range of stimuli (e.g. abstract shapes/tangrams) where behavior in the lab isn't totally dominated by strong prior conventions people bring into the interaction. 
%For example, similar phenomena Pictionary games where participants use a whiteboard to draw messages instead of an auditory or text-based channel \cite{GarrodFayLeeOberlanderMacLeod07_GraphicalSymbolSystems,TheisenEtAl10_SystematicityArbitrariness,hawkins2019disentangling}.

%Another modality-based manipulation is to attempt to destroy or scramble any meaningful priors that people might carry into the social interaction.
%For example, \citeA{Galantucci05_EmergenceOfCommunication} introduced a novel `seismograph' interface for communication -- a stylus that could be moved side-to-side or lifted up or down to make contact with the sketch pad while the vertical dimension drifted downward at a constant rate.
%The resulting messages consequently look nothing like the usual kinds of symbols people create: the relationship between motor actions and perceptual output is broken such that executing a familiar movement for a symbol or numeral instead produces an odd, wavy scribble.
%Despite the relative lack of priors on signal meanings in this medium, people were nevertheless able to converge on successful signaling systems in repeated reference games \cite<see also>{RobertsGalantucci12_DualityOfPatterning,RobertsEtAl15_IconocityOnCombinatoriality}.
%Other novel modalities used in iterated reference games include a `whistle' language where movements along a vertical touch bar slider correspond to changes in pitch \cite{VerhoefRobertsDingemanse15_Iconicity} and a visual analog where movements along the slider were presented visually \cite{VerhoefEtAl16_TemporalLanguage}.
%
%\subsection{The role of feedback and backchannels}
%\todo[]{(I'm pretty sure direct feedback isn't needed for reduction in general:  notice we initially introduce a new individual into the discourse with a name or description, but  we subsequently simply use a pronoun (shorter) or omit -- we don't need feedback to do this. This is a section that I'd consider omitting as the type of feedback that's provided here is pretty specific to this game; you're also citing quite old literature here, so its less newsworthy and the idea that we don't reduce partially for ourselves is less convincing than other parts of the paper }
%
%If convention formation is grounded in inference, then an important corollary of our model is that the extent to which partners are able to coordinate should depend critically on the observations $D_i$ they condition on in Eq.~\ref{eq:joint_inference}.
%In the \emph{complete} absence of feedback --- when the speaker is instructed to repeatedly refer to a set of objects for a listener who is not present and will do their half of the task offline --- there is no reduction in message length \citeA{HupetChantraine92_CollaborationOrRepitition}. 
%
%Our simulations examined the most minimal sources of feedback: the speaker's utterance and the listener's response in a reference game.
%A key direction for future work is to account for richer forms of feedback that arise in natural communication.
%For example, a key feature of dialogue is the capacity for a \emph{real-time back-channel}.
%The listener may say anything at any point in time, thus allowing for interjections (uh-huh, hmmm, huh?), clarification questions, and other listener-initiated forms of feedback. 
%Elaborating the generative model of the listener to include these verbal behaviors will be critical to explaining other key results from \citeA{ClarkWilkesGibbs86_ReferringCollaborative}, including changes in the frequency of listener-initiated feedback over the course of interaction.
%
%Additionally, such an elaboration would allow our model to address early empirical results from \citeA{KraussWeinheimer66_Tangrams} manipulating the feedback channel: participants were able to talk bidirectionally in one condition but in another condition, the channel was unidirectional. 
%The speaker was prevented from hearing the listener's responses. 
%This feedback manipulation was crossed with a behavioral feedback manipulation where the experimenters intercepted the listener's responses: one group of speakers was told that their partner made the correct response 100\% of the trials (regardless of their real responses), while another was told on half of the trials that their partner made the incorrect response. 
%Our account of increasing efficiency (\textbf{P1}) predicts that speaker may not have sufficient evidence to justify shorter utterances in the absence of evidence about how their longer descriptions are being interpreted.
%Indeed, \citeA{KraussWeinheimer66_Tangrams} found that both channels contribute independently to gains in efficiency.
%Speakers kept using longer utterances when they observed that their partner was making errors. 
%But blocking the real-time verbal back-channel significantly limited reduction, even when told that their partner was achieving perfect accuracy.
%%Speakers converged to utterances that were about twice as long as those found when verbal feedback was allowed.
%In the extreme case of trying to communicate to a listener who can't respond and also appears to not understand, speaker utterance length actually \emph{increased} with repetition after an early dip. 
%
%More graded disruptions of feedback seem to force the speaker to use more words overall but not to significantly change the rate of reduction. 
%For example, \citeA{KraussBricker67_Delay} tested a transmission delay to temporally shift feedback and an access delay to block the onset of listener feedback until the speaker is finished. 
%Later, \citeA{KraussEtAl77_AudioVisualBackChannel} replicated the adverse effect of delay but showed that undelayed visual access to one's partner cancelled out the effect and returned the number of words used to baseline. 
%On the listener's part, too, the ability to actively \emph{give} feedback appears critical for coordination. 
%\citeA{SchoberClark89_Overhearers} showed that even listeners who \emph{overheard} the entire game were significantly less accurate than listeners who could directly interact with the speaker, even though they heard the exact same utterances, presumably because the speaker was not able to take their particular sources of confusion into account.
%Our model provides a formal framework to begin probing how these different forms of communicative feedback may license different inferences about one's partner in interaction.

\subsection{The role of social knowledge}
%\adele{You focus on \textit{new} referring expressions, but I wonder if you could extend to existing expressions too by thinking about the role of frequency/entrenchment.

%\todo[]{this isn't a todo at all, but I bet the same uncertainty and generalization with evidence of broader use is relevant to contexts as well as individuals: if you order a 'cup of coffee' in Italy, you may get espresso; we can change our conventions even with the same people in  different contexts: individuals (especially unusual individuals) provide a clear indication of context}

%  1) A reviewer asks whether common ground or authority is most relevant: I think that difference determines how far a new expression is likely to spread. Random groups of speakers don't get to name things that are relevant to most speakers of a language:  (typically?) a small group of visible &/or respected people name the new thing and the rest of us go along with that term pretty quickly,reducing when they reduce. To your point, we may still alternate with a longer phrases esp when there's lack of common ground: 'Jan 6th insurrection' 'COVID19', 'the Delta variant'). T

% 2) For terms we already have a referring expression for, we often resist  change so if it occurs at all, it'd be on a  much slower time scale: probably because the term is too entrenched for us to bother bringing it to a larger group, or perhaps when we feel it reflects our membership in a group (see hoagie/sub; on line/in line; shore/beach; 

% --> Authority (sometimes localized sometimes diffuse) and prior FREQUENCY/entrenchment play a role in how likely a speaker is to adapt and so how likely or quickly a change in the language is (associations surely predict this).

\todo[]{(I'd also consider eliminating this section if you want to simplify the general discussion, for similar reasons; the model doesn't include social information beyond identity. Down the line it'd be useful to use this sort of hierarchical grouping or even better, potentially dynamic clustering depending on contexts, to account for why some words are limited to specific contexts as well as specific people: e.g, Thing 1 and Thing 2 are associated with Dr. Suess books, subway with NY; BART with Bay Area.)}
Real-world communities are much more complex than the simple networks we considered: each speaker takes part in a number of overlapping subcommunities, and may be more centrally or peripherally involved with stronger or less strong priors in each. 
For example, we use partially distinct conventions depending on whether we are communicating with psychologists, friends from high school, bilinguals, or children \cite{auer_code-switching_2013}.
When a scientist is talking to other scientists about their work, they know they can use efficient technical shorthand that they would avoid when talking to their non-expert friends and family. 
Previous work has probed representations of community membership by manipulating the extent to which cultural background is shared between speaker and listener.
For example, \citeA{IsaacsClark87_ReferencesExpertsNovices} paired participants who had either lived in NYC or had never been there for a task referring to landmarks in the city (e.g. ``Rockefeller Center''). 
Within just a few utterances from a novel partner, people could infer whether they were playing with an expert or novice and immediately adjust their language use to be appropriate for this inferred identity. 
Social information about a partner’s group can be so important that even players in artificial-language games react to the restrictions of social anonymity by learning to identify members of their community using distinctive signals \cite{roberts_experimental_2010}.

For future work using hierarchical Bayesian models to address the full scale of an individual's  network of communities, additional social knowledge about these communities must be learned and represented in the generative model.
Larger-scale networked experiments can be used to evaluate the hypothesis that a hierarchical representation of conventions includes not just a partner-specific level and population-wide level but also intermediate community levels. 
This hypothesis can be formalized by including additional latent representations of community membership into our hierarchical model.
That is, in addition to updating our model of a particular \emph{partner} based on immediate feedback, even sparse observations of a partner's language use may license much broader inferences about their lexicon via diagnostic information about their social group or background. 
If someone's favorite song is an obscure B-side from an 80s hardcore band, you can make fairly strong inferences about what else they like to listen to and how similar they might be to you \cite{VelezEtAl16_Overlaps, GershmanEtAl17_StructureSocialInfluence}. 
Similarly, if someone casually refers to an obscure New York landmark, you may be able to update your beliefs not just about that lexical item but about a number of other lexical conventions shared among New Yorkers. 
Lexica cluster within social groups, so inverting this relationship can yield rapid lexical learning from inferences about social group membership.

This explanation is also consistent with broader linguistic phenomena outside the realm of repeated reference games. 
For example, \citeA{PottsLevy15_Or} showed that lexical uncertainty is critical for capturing constructions like \emph{oenophile or wine lover}, where a disjunction of synonymous terms is taken to convey a definition -- information about the speaker's lexicon -- rather than a disjoint set. 
While the reasons that speakers produce such constructions are complex, we would expect that speakers will be more likely to produce the definitional \emph{or} when the component word is expected to be rarer or more obscure for a particular partner: when there is additional uncertainty over its likely meaning in the listener's lexicon.


\subsection{Process-level mechanisms for adaptation}

Finally, while we have provided a computational-level account of coordination and convention formation in terms of hierarchical inference, there remain many possible process-level mechanisms that may perform this computation.
In this section, we discuss two interlocking process-level questions: (1) exactly which representations are being adapted? (2) how does our model scale to larger spaces of utterances and referents? %and (3) what memory systems are required for tracking and generalizing partner-specific meanings?

\todo[]{I find "utterances and referents" a weird conjunction since utterances usually include relational information, are not just pointers to referents. Maybe 'descriptions and referents' instead?}
\todo[]{some mention of frequency or accessibility seems important: more entrenched/more accessible memories are less likely to adapt; this would make children more adaptable than adults who have more experience and better retrieval skill; would also make shorter forms preferable not becuase efficiency is a goal but because shorter forms are ceteris paribus more accessible}

%\subsection{Memory systems supporting generalization}
%
% \cite{horton_revisiting_2016}.

\subsubsection{Which representations are adapted?}
\todo[]{this subsection is great and seems really relevant and important, nice!}
While our model formulation focused on adaptation at the level of the lexicon (i.e. inferences about $\phi$, representing different possible lexical meanings), this is only one of many internal representations that may need to be adapted to achieve successful coordination. 
Three other possible representational bases have been explored in the literature. 

First, it is possible that adaptation takes place upstream of the lexicon, directly implicating perceptual or \emph{conceptual} representations \cite{GarrodAnderson87_SayingWhatYouMean,HealeySwobodaUmataKing07_GraphicalLanguageGames}
That is, there may be uncertainty about how a particular partner construes the referent itself, and communication may require constructing a shared, low-dimensional conceptual space where the relevant referents can be embedded \cite{stolk2016conceptual}.
This is particularly clear in the classic maze task \cite{GarrodAnderson87_SayingWhatYouMean} where giving effective spatial directions requires speakers to coordinate on what spatial representations to use (e.g. paths, coordinates, lines, or landmarks). 

Second, it is possible that adaptation takes place even further upstream, at the level of \emph{social} representations \cite{jaech2018low}.
Rather than directly updating beliefs about lexical or conceptual representations, we may update a holistic representation of the partner themselves (e.g. as a ``partner embedding'' in a low-dimensional vector space) that is used to retrieve downstream conceptual and lexical representations. 
Under this representational scheme, the mapping from the social representation to particular conventions is static, and \emph{ad hoc} adaptation is limited to learning where a particular partner belongs in the overall social space.

Third, it is possible that expectations about other lower-level features of a partner are also adapted through interaction.
For example, interactive alignment accounts \cite{pickering2004toward} have argued that activating phonetic or syntactic features that are associated with specific lemmas in the lexicon can percolate up to strengthen higher levels of representation \cite{roelofs1992spreading,pickering1998representation}.
Thus, learning about a partner's word frequency \cite{louwerse2012behavior}, syntax \cite{gruberg2019syntactic,levelt1982surface}, body postures \cite{lakin2003using}, speech rate \cite{giles1991contexts}, or even informational complexity \cite{abney2014complexity} could be functionally useful for communication if they covary with, or are informative about, higher-level representations. 

\subsubsection{Scalability to larger utterance and referent spaces}
\todo[]{tbh, I like this section but I'd reframe it as  'limitations' or 'future work' as it's not truly a  convincing description of how to scale the model up, do you think? I mean we learn all sorts of constructions for all sorts of contexts and we even speak with the same people in different ways depending on context; reference games with orthogonal features or objects is a little corner. I mean you've done a lot! you're pointing out important limitations here for the most part }
To allow for the fact that an utterance may be learned to apply appropriately in one context but be inappropriate in another, the forgetting function must operate on the pairing of an utterance and its interpretation \textit{in context}.
Less recent utterances that were used to express the same interpretation-in-context  become less accessible over time, but utterances with a distinct interpretation-in-context should be unaffected. 
%include?: The current work addresses the complex issue of what should count as the same context by means of the hierarchical Bayesian model.

While a fully Bayesian formulation elegantly captures the inference problem at the core of our theory, the posterior update step in Eq.~\ref{eq:joint_inference} grows increasingly intractable as the space of utterances and referents grows. 
This computational limitation is especially evident when considering how to quantitatively fit models to the natural-language data produced in unconstrained reference games, or applications in modern machine learning where we would like to build artificial agents that can adapt to human partners.
Generalizing our framework to the arbitrary natural language (e.g. referring expressions using the full vocabulary of an adult language user) and arbitrary visual input (e.g. sensory impressions of novel objects such as tangrams) that are the basis for natural communication not only requires a different representational space for language and visual input, it may require different inference algorithms. 

The first computational obstacle is the lexical representation.
A discrete $m\times n$ matrix containing entries for each utterance-referent pair, as typically used in convention formation simulations, has two primary limitations as a proxy for human representations: (1) it  grows quadratically as additional utterances and referents are added while becoming increasingly sparse (i.e. most words only apply to a relatively small set of referents) and (2) it does not straightforwardly represent similarity relationships between utterances and referents (i.e. a new referent must be added as a distinct new column, even if it is visually similar to a known referent).
This limitation is especially clear when referents are presented as raw images. 

The second computational obstacle is the inference algorithm.
Even if a more scalable family of lexical representations $\mathcal{L}_\phi$ is chosen, any parameterization $\phi$ of this representation will be much higher-dimensional than we have considered.
For example, if $(\Theta, \phi)$ are defined to be the weights of a neural network, then maintaining uncertainty $P(\Theta, \phi)$ would require placing a prior over the weights and the posterior update $P(\Theta, \phi | D)$ would require a difficult integral over a very high-dimensional support, or a type of (hierarchical) Bayesian neural network \cite{mackay1992practical,neal2012bayesian}.
While recent algorithmic breakthroughs have made (approximate) inference for such networks increasingly tractable \cite<e.g.>{hernandez2015probabilistic,lacoste2018uncertainty,dusenberry2020efficient,izmailov2020subspace}, they remain untested as cognitive models.

While these obstacles are significant, we argue that our hierarchical Bayesian framework is nonetheless well-poised to explain coordination and convention-formation at scale. 
\todo[]{this sounds really intriguing and I'd  keep it in, but there's not enough information here to convince a skeptical reader that this means the current model can scale up without giving up the goal of connecting initial learning and convention formation suggested in subsection above. Vector representations have the benefit of allowing for some type of similarity metric, but then it's not clear how that would work with the RSA model that assumes sets (which are unstructured collections). so I dunno, 'well-poised to explain at scale' seems bold}
In particular, recent formal connections between hierarchical Bayes and gradient-based meta-learning approaches in machine learning \cite{grant_recasting_2018} suggest an alternative algorithm that relaxes the full prior over $\Theta$ to a point estimate and replaces the difficult integral in the posterior update with a handful of (regularized) gradient steps. 
This more tractable algorithm approximates the same computational-level problem we have formulated but provides a different perspective: conventions are learned \emph{initializations} and coordination is partner-specific \emph{fine-tuning} or \emph{domain adaptation} of vector representations. 
The fine-tuning approach, initializing with a state-of-the-art neural language model, has recently accounted for psycholinguistic data on reading times \cite{van2018neural} as well as \emph{ad hoc} convention formation in reference games using (unseen) natural images as referents \cite{hawkins2019continual}.

\paragraph{Conclusion}

We have argued that successful communication depends on continual learning across multiple timescales. 
We must coordinate on \emph{ad hoc} meaning through common ground with individual partners but also abstract these experiences away to represent stable, generalizable \emph{conventions} and norms.
Like other socially-grounded knowledge, language is not a rigid dictionary that we acquire at an early age and deploy mechanically for the rest of our lives. 
Nor does language only change over the slow time-scales inter-generational drift.
Language is a means for communication -- a shared interface between minds -- and must therefore adapt over the rapid contextual timescales required by communication.
As new \emph{ad hoc} concepts arise, new \emph{ad hoc} conventions must be formed to solve the new coordination problems they pose.
In other words, we are constantly learning language. 
Not just one language, but a family of related languages, across interactions with each partner. 

\begin{quote}
\emph{Let us conclude not that ‘there is no such thing as a language’ that we bring to interaction with others. Say rather that there is no such thing as the one total language that we bring. We bring numerous only loosely connected languages from the loosely connected communities that we inhabit.} \cite{hacking1986nice}
\end{quote}
