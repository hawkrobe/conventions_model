%!TEX root = ../dissertation.tex
In this paper, we considered the computational challenges posed by communication in a variable and non-stationary landscape of meaning.
We advanced a hierarchical Bayesian approach  in which agents continually adapt their beliefs about the form-meaning mapping used by each partner, in turn.
We formalized this approach by integrating three core cognitive capacities in a probabilistic framework: representing initial uncertainty about what a partner thinks words mean \textbf{(C1)}, partner-specific adaptation based on observations of language use in context \textbf{(C2)}, and hierarchical structure for graded generalization to new partners \textbf{(C3)}.
This unified model resolves several puzzles that have posed challenges from prior models of coordination and convention formation: why referring expressions shorten over repeated interactions with the same partner \textbf{(P1)}, how partner-specific common ground may coexist with the emergence of conventions at the population level \textbf{(P2)}, and how context shapes which conventions emerge \textbf{(P3)}.

We conclude by raising five broader questions that follow from the theoretical perspective we have advanced, each suggesting pathways for future work: (1) are the mechanisms underlying \emph{ad hoc} convention formation in adults the same as those underlying language acquisition in children? (2) to what extent do these mechanisms depend on the communication modality? (3) what kinds of feedback are used to coordinate on conventions? (4) what kinds of social structure are reflected in the hierarchical prior, and (5) which representations are involved in adaptation at a process-level?

\subsection{Continuity of language learning across development}

There is a close mathematical relationship between our model of convention formation and recent probabilistic models of word learning in developmental science \cite<e.g.>{XuTenenbaum07_WordLearningBayesian,FrankGoodmanTenenbaum09_Wurwur}. 
This similarity suggests an intriguing conjecture that the continual-learning mechanisms adults use to rapidly coordinate on partner-specific conventions may be the same as those supporting lexical acquisition in children.
In other words, people may never stop learning language; they may simply develop stronger and better-calibrated beliefs about their community's conventions, which apply to a broader swath of communicative scenarios.
In this section, we discuss three possible implications of viewing language development in terms of social coordination and convention.

First, common paradigms for cross-situational learning typically assume a fixed speaker and focus on variability across referential contexts \cite{siskind1996computational,regier2005emergence,smith2014unrealized,yurovsky2015integrative}. 
Yet, as we have argued, variability in how words are used by different \emph{partners} may pose an equally challenging problem.
While there has been limited work on the social axis of generalization, it is increasingly apparent that children are able to track \emph{who} produced the words they are learning and use this information to determine whether word meanings should generalize not just to other contexts but also to other speakers.
For example, young children may limit the generalizability of observations from speakers who use language in idiosyncratic ways, such as a speaker who call a ball a ``dog'' \cite{koenig2010sensitivity,luchkina2018eighteen}, and even retrospectively update beliefs about earlier words after observing such idiosyncracies \cite{dautriche2021}.

This discounting behavior may be understood as an instance of the same inductive problem that convention formation poses for adults in \textbf{P2}.
Unlike complete-pooling models, which predict that all observations should be taken as equally informative about the community's conventions, our hierarchical model predicts that children should be able to explain away ``outliers'' without their community-level expectations being disrupted.
Indeed, a novel prediction generated by our account is that children should be able to accommodate idiosyncratic language \emph{within} extended interaction with the same speaker (e.g. continue to pretend the ball is called ``dog,'' given partner-specific common ground) while also limiting generalization of that convention \emph{across} other speakers.

Second, we have emphasized the importance of representing lexical \emph{uncertainty}, capturing expected variability in the population beyond the point estimates assumed by traditional lexical representations. 
But how do children calibrate their lexical uncertainty?
One possibility assigns a key role to the number of distinct speakers in a child's environment.
Exposure to fewer partners may result in weaker \cite<e.g.>{lev2017talking} or mis-calibrated priors.
If an idiosyncratic construction is over-represented in the child's environment, they may later be surprised to find that it was specific to their household's lexicon and not shared by the broader community  \cite<see>[Chap. 6]{Clark09_FirstLanguageAcquisition}. 
Conversely, however, hierarchical inference predicts a blessing of abstraction \cite{GoodmanUllmanTenenbaum11_TheoryOfCausality}: under certain conditions, community-level conventions may be inferred even with relatively short sparse observations from each partner.
To resolve these questions, future work will need to develop new methods for eliciting children's expectations about partner-specificity and variability of meanings.

Third, our work suggests a new explanation for why young children may struggle to coordinate on \emph{ad hoc} conventions with one another in repeated reference games \cite{GlucksbergKraussWeisberg66_DevoRefGames,KraussGlucksberg69_DevoReferenceGames,KraussGlucksberg77_SocialNonsocialSpeech}. 
%When an experimenter feeds them messages produced by adult speakers in other games, they are able to maintain high accuracy even as the utterance reduce down to one- or two-word label. 
%When Kindergarteners play with one another, however, they continue to make errors even after 15 repetitions.
Children as old as fifth grade only improve with assistance from the experimenter \cite{matthews2007toddlers}: instead of beginning with the long indefinite descriptions that adults provide, it was observed that children began with shorter descriptions like \emph{Mother's dress} \cite<see also>{kempe2019adults}.
While these failures were initially attributed to limits on theory of mind use, this explanation has been complicated by findings that children cannot even interpret their own utterances after a delay \cite{asher1976children}. 
In other words, errors are not well-explained by egocentric adherence to a strongly preferred label, or downstream failures to acknowledge that this preferred label may not be understood by their partner; there appears to be no such preferred label.

Our model raises the possibility that the problem may instead stem from production with an impoverished lexical prior: there are no existing conventions for such a novel object in their vocabulary \cite{goldberg2019explain}, leaving their preferences dispersed widely over ``good-enough'' constructions.
Indeed, when children are paired with their caregivers rather than peers, they are able to successfully form conventions \citeA{LeungEtAl20_Pacts}.
Parents helped to interactively scaffold these conventions, both by proactively seeking clarification in the listener role \cite<e.g.>{anderson1994interactive} and by providing more descriptive labels in the speaker role, which children adopted themselves on later trials.
These results highlight one way in which our model of convention formation may coincide with models of language acquisition in development: in both cases, listeners are trying to infer the meanings of words in the speaker's lexicon. 

While we have highlighted three particular developmental phenomena where our approach may generate novel predictions, there are many finer-grained questions raised by our computational approach.
For example, is the child's lexical expectations in communication best explained as a (resource-limited) representation of \emph{others'} lexicons, or as an egocentric (asocial) epistemic state? 
To what extent is the ability to retrieve or use this lexical prior constrained by theory of mind development? 
Even infants are sensitive to coarse social distinctions based on foreign vs. native language \cite{KinzlerDupouxSpelke07_LanguageGroups}, or accent \cite{KinzlerEtAl09_AccentRace}, but when do fully partner-specific representations develop?

\subsection{The role of communication modality}

%\begin{quote}
%The oral modality is not well suited to conveying messages mimetically (i.e., iconically), even though that function is also important to human languages. This function is, however, very well served by the manual modality. \cite[p.155]{}
%\end{quote}

While we have focused primarily on verbal and textual communication channels, there has beens significant progress understanding the dynamics of adaptation in other communication modalities, including graphical \cite{GarrodFayLeeOberlanderMacLeod07_GraphicalSymbolSystems,TheisenEtAl10_SystematicityArbitrariness,hawkins2019disentangling} gestural \cite{FayListerEllisonGoldinMeadow13_GestureBeatsVocalization,motamedi2019evolving,bohn2019young} and other \emph{de novo} modalities \cite{Galantucci05_EmergenceOfCommunication,RobertsGalantucci12_DualityOfPatterning,RobertsEtAl15_IconocityOnCombinatoriality,VerhoefRobertsDingemanse15_Iconicity,VerhoefEtAl16_TemporalLanguage,kempe2019adults}.
These modalities are important for our account in several ways.

First, it is a core claim of our hierarchical model that the basic cognitive mechanisms underlying adaptation and convention formation are domain-general.
In other words, there should be nothing inherently special about spoken or written language: any system that humans use to communicate should display similar \emph{ad hoc} learning dynamics because in every case people are simply trying to infer the system of meaning being used by their partner.
Directly comparing behavior in repeated reference games across different modalities is therefore necessary to determine which adaptation effects, if any, are robust and attributable to modality-general mechanisms.

Second, at the same time, our hierarchical learning model predicts a critical role for the priors we build up across interactions with many individuals.
We therefore predict that different communication modalities should display certain systematic differences due to the representational structure of the communication channel.
For example, in the verbal modality, the tangram shapes from \citeA{ClarkWilkesGibbs86_ReferringCollaborative} are highly ``innominate'' -- most people do not have much experience naming or describing them with words, so the global prior is weak and local adaptation plays a greater role.
In the graphical modality, where communication takes place by drawing on a shared sketchpad, people can be expected to have a stronger prior rooted in assumptions about shared perceptual systems and visual similarity \cite{fan2018common} -- drawing a quick sketch of the tangram's outline may suffice for understanding.

Other stimuli have precisely the opposite property: to distinguish between natural images of dogs, people may have strong existing conventions in the linguistic modality (e.g. `husky', `poodle', `pug') but drawing the necessary fine distinctions in the graphical modality may be initially very costly for novices \cite{fan2020pragmatic}, requiring the formation of local conventions to achieve understanding. 
Gesture also has its own distinctive prior, which also allows communicators to use time and the space around them to convey mimetic or depictive meanings that may be difficult to encode verbally or graphically \cite{goldin-meadow_role_1999,clark2016depicting,mcneill1992hand}. 
Our model ought to be able to account for production and comprehension across these modalities by eliciting modality-specific priors on meaning.

%If we adhered solely to the verbal modality, we would be limited to a fairly narrow range of stimuli (e.g. abstract shapes/tangrams) where behavior in the lab isn't totally dominated by strong prior conventions people bring into the interaction. 
%For example, similar phenomena Pictionary games where participants use a whiteboard to draw messages instead of an auditory or text-based channel \cite{GarrodFayLeeOberlanderMacLeod07_GraphicalSymbolSystems,TheisenEtAl10_SystematicityArbitrariness,hawkins2019disentangling}.

%Another modality-based manipulation is to attempt to destroy or scramble any meaningful priors that people might carry into the social interaction.
%For example, \citeA{Galantucci05_EmergenceOfCommunication} introduced a novel `seismograph' interface for communication -- a stylus that could be moved side-to-side or lifted up or down to make contact with the sketch pad while the vertical dimension drifted downward at a constant rate.
%The resulting messages consequently look nothing like the usual kinds of symbols people create: the relationship between motor actions and perceptual output is broken such that executing a familiar movement for a symbol or numeral instead produces an odd, wavy scribble.
%Despite the relative lack of priors on signal meanings in this medium, people were nevertheless able to converge on successful signaling systems in repeated reference games \cite<see also>{RobertsGalantucci12_DualityOfPatterning,RobertsEtAl15_IconocityOnCombinatoriality}.
%Other novel modalities used in iterated reference games include a `whistle' language where movements along a vertical touch bar slider correspond to changes in pitch \cite{VerhoefRobertsDingemanse15_Iconicity} and a visual analog where movements along the slider were presented visually \cite{VerhoefEtAl16_TemporalLanguage}.

\subsection{The role of feedback and backchannels}

If adaptation is learning, then an important corollary of our model is that the extent to which partners adapt should depend critically on the quality of the data $D_i$ on which they are conditioning: $P(\mathcal{L}_i | \Theta, D_i)$.
Our simulations used the simplest source of feedback: the utterance and response in a reference game.
A key direction for future work is to account for richer forms of feedback.
For example, a key feature of dialogue is the capacity for a \emph{real-time back-channel}.
Either individual may say anything at any point in time, thus allowing for interjections (uh-huh, hmmm, huh?), clarification questions, and other listener-initiated forms of feedback. 
Without elaborating the generative model of the listener to include these verbal behaviors, we cannot explain the inferences a speaker will make upon hearing them.
Such an elaboration will thus be critical to explaining why listeners send fewer messages over time and what impact early listener responses on conventionalization. 

Additionally, this elaboration would allow our model to capture early, important empirical results from \citeA{KraussWeinheimer66_Tangrams}, which manipulated the feedback channel.
In one condition, participants were able to talk bidirectionally, and in another the channel was unidirectional: the speaker was unable to hear the listener's responses. 
This real-time feedback manipulation was crossed with a behavioral feedback manipulation where the experimenters intercepted the listener's responses: one group of speakers was told that their partner made the correct response 100\% of the trials (regardless of their real responses), while another was told on half of the trials that their partner made the incorrect response. 

Under our account, if the speaker is unsure how their longer descriptions are being interpreted -- unsure whether or not they can get away with shorter, more ambiguous expressions -- they may not have enough evidence about meanings to justify shorter utterances. 
Indeed, \citeA{KraussWeinheimer66_Tangrams} found that even when told that their partner was getting 100\% correct, entirely blocking the verbal feedback channel significantly limited the reduction effect. 
Speakers converged to utterances that were about twice as long as those found when verbal feedback was allowed.
Telling speakers that their partner was performing poorly also inhibited reduction as a main effect. 
In the extreme case of trying to communicate to a listener who can't respond and appears to not understand, speaker utterance length actually increased with repetition after an early dip. 
\citeA{HupetChantraine92_CollaborationOrRepitition} found that in the \emph{complete} absence of feedback --- when the speaker is instructed to repeatedly refer to a set of objects for a listener who is not present and will do their half of the task offline --- there is also no reduction in message length. 

More graded disruptions of feedback seem to force the speaker to use more words overall but not to significantly change the rate of reduction. 
For example, \citeA{KraussBricker67_Delay} tested a transmission delay to temporally shift feedback and an access delay to block the onset of listener feedback until the speaker is finished. 
Later, \citeA{KraussEtAl77_AudioVisualBackChannel} replicated the adverse effect of delay but showed that undelayed visual access to one's partner cancelled out the effect and returned the number of words used to baseline. 
On the listener's part, too, the ability to actively \emph{give} feedback appears critical for coordination. 
\citeA{SchoberClark89_Overhearers} showed that even listeners who \emph{overheard} the entire game were significantly less accurate than listeners who could directly interact with the speaker, even though they heard the exact same utterances.
Our model provides an initial framework to begin understanding how these subtle manipulations of feedback channels license differing inferences about a partner's underlying system of meaning \ks{I wasn;t sure why this last sentence followed - can you explain a bit more?}.

\subsection{The role of social knowledge}

Real-world communities are much more complex than the simple networks we considered: each speaker takes part in a number of overlapping subcommunities. 
For example, we use partially distinct conventions depending on whether we are communicating with psychologists, friends from high school, bilinguals, or children \cite{auer_code-switching_2013}.
For instance, when a scientist is talking to other scientists about their work, they know they can use efficient technical shorthand that they would avoid when talking to their non-expert friends and family. 
Previous work has probed representations of community membership by manipulating the extent to which cultural background is shared between speaker and listener.
For example, \citeA{IsaacsClark87_ReferencesExpertsNovices} paired participants who had either lived in NYC or had never been there for a task referring to landmarks in the city (e.g. ``Rockefeller Center''). 
Within just a few utterances from a novel partner, people could infer whether they were playing with an expert or novice and immediately adjust their language use to be appropriate for this inferred identity. 
Social information about a partner’s group can be so important that even players in artificial-language games react to the restrictions of social anonymity by learning to identify members of their community using distinctive signals \cite{roberts_experimental_2010}.

For future work using hierarchical Bayesian models to address the full scale of an individual's  network of communities, additional social knowledge about these communities must be learned and represented in the generative model.
Larger-scale networked experiments can be used to evaluate the hypothesis that a hierarchical representation of conventions includes not just a partner-specific level and population-wide level but also intermediate community levels. 
This hypothesis can be formalized by including additional latent representations of community membership into our hierarchical model.
That is, in addition to updating our model of a particular \emph{partner} based on immediate feedback, even sparse observations of a partner's language use may license much broader inferences about their lexicon via diagnostic information about their social group or background. 
If someone's favorite song is an obscure B-side from an 80s hardcore band, you can make fairly strong inferences about what else they like to listen to and how similar they might be to you \cite{VelezEtAl16_Overlaps, GershmanEtAl17_StructureSocialInfluence}. 
Similarly, if someone casually refers to an obscure New York landmark you also recognize, you can safely update your beliefs about their lexicon to include a number of other conventions shared among New Yorkers. 
Lexica cluster within social groups, so inverting this relationship can yield rapid lexical learning from inferences about social group membership.

This explanation is also consistent with broader linguistic phenomena outside the realm of repeated reference games. 
For example, \citeA{PottsLevy15_Or} showed that lexical uncertainty is critical for capturing constructions like \emph{oenophile or wine lover}, where a disjunction of synonymous terms is taken to convey a definition -- information about the speaker's lexicon -- rather than a disjoint set. 
While the reasons that speakers produce such constructions are complex, we would expect that speakers will be more likely to produce the definitional \emph{or} when the component word is expected to be rarer or more obscure for a particular partner: when there is additional uncertainty over its likely meaning in the listener's lexicon.


\subsection{Process-level mechanisms for adaptation}

While our model has been formulated in terms of coordination on \emph{lexical} meaning, this is only one of many levels at which conventions may form. 
In more complex circumstances, there is often initial uncertainty not just about which of a small set of targets a particular message refers to, but how to represent the relevant targets of reference in the first place. 
Learning to communicate effectively may require discovering a lower-dimensional representation in which the targets of reference vary.
For instance, when using sketches to communicate about the identity of complex pieces of music \cite{HealeySwobodaUmataKing07_GraphicalLanguageGames}, a particular set of strokes could correspond to any number of properties (pitch, tempo, melody, rhythm, intensity) at any temporal granularity. 
This is made particularly clear in a classic maze game \cite{GarrodAnderson87_SayingWhatYouMean}: in order to give effective spatial directions, speakers apparently had well-tuned lexical priors but had to coordinate on what space of \emph{referents} to use (e.g. paths, coordinates, lines, landmarks). 

By appealing to classic spreading-activation connectionist models \cite<e.g.>{roelofs1992spreading}, interactive alignment accounts \cite{pickering2004toward} have argued that activating phonetic or syntactic features that are associated with specific lemmas in the lexicon can percolate to strengthen higher semantic levels of representation \cite{pickering1998representation}.
Thus, unconsciously coupling word choices \cite{louwerse2012behavior}, syntax \cite{gruberg2019syntactic,levelt1982surface}, body postures \cite{lakin2003using}, speech rate \cite{giles1991contexts}, or even informational complexity \cite{abney2014complexity} in dialogue could potentially contribute to the coordination of higher-level semantic representations. \ks{not sure what the point of this paragraph was}

Other theories have assumed representations of lexical meanings are relatively fixed and the only learning taking place is how one's partner construes a multi-stable percept. 
For examine, this seems to be what \citeA{BrennanClark96_ConceptualPactsConversation} had in mind when they coined the term \emph{conceptual pact}, and \citeA{stolk2016conceptual} have influentially argued that partners in communication construct shared conceptual spaces. 
Given present data it is not clear how these two sources of uncertainty could be teased apart \ks{I am not sure what the two sources of uncertainty are!}, though certain kinds of conventions (e.g. proper names or acronyms) seem to rely more on binding new linguistic tokens to meanings than on constructing new conceptualizations.
Thus, we expect both levels of coordination are likely to play an important role. 
Our probabilistic model could be extended to handle additional levels of coordination by placing uncertainty over a hyper-parameter corresponding to the intended feature dimension that must be jointly inferred with the correspondence along that dimension. 

%\rdh{TODO: paragraph citing Hawkins, Kwon, Sadigh, Goodman to argue that gradient-based meta-learning with neural network representation is an alternative architecture that is more computationally tractable at scale than a fully probabilistic model?}


\paragraph{Conclusion}

Language is not a rigid body of knowledge that we acquire at an early age and deploy mechanically for the rest of our lives. 
Nor is its evolution a slow, inter-generational drift. \ks{hey, is that a dig at iterated learning? :-)}
It is a means for communication -- a shared interface between minds -- and must therefore adapt over the rapid timescales required by communication. 
In other words, we are constantly learning language. 
Not just one language, but a family of related languages, across every repeated interaction with every partner. 

\begin{quote}
Let us conclude not that ‘there is no such thing as a language’ that we bring to interaction with others. Say rather that there is no such thing as the one total language that we bring. We bring numerous only loosely connected languages from the loosely connected communities that we inhabit. \citeA{hacking1986nice}
\end{quote}
