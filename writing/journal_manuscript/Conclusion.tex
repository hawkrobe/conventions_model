Communication in a variable and non-stationary landscape of meaning creates unique computational challenges.
To address these challenges, we advanced a hierarchical Bayesian approach  in which agents continually adapt their beliefs about the form-meaning mapping used by each partner, in turn.
We formalized this approach by integrating three core cognitive capacities in a probabilistic framework: representing initial uncertainty about what a partner thinks words mean \textbf{(C1)}, partner-specific adaptation based on observations of language use in context \textbf{(C2)}, and hierarchical structure for graded generalization to new partners \textbf{(C3)}.
This unified model resolves several puzzles that have posed challenges for prior models of coordination and convention formation: why referring expressions shorten over repeated interactions with the same partner \textbf{(P1)}, how partner-specific common ground coexists with the emergence of conventions at the population level \textbf{(P2)}, and how context shapes which conventions emerge \textbf{(P3)}.

We conclude by raising three broader questions that arise from the perspective of our model, each suggesting pathways for future work: (1) to what extent is \emph{ad hoc} convention formation in adults the same as word learning in children and how is it different? (2) to what extent do the proposed mechanisms depend on the communication modality? and (3) which representations are involved in adaptation at a process-level? 

\subsection{Continuity of language learning across development}

CHAI aims to shift the central computational problem of communication from transmission to learning and adapation. 
Although it is intended as a theory of \emph{adult} communication among mature language users, our emphasis on learning has much in common with theories of language acquisition in development.
Could the basic cognitive mechanisms allowing adults to coordinate on conventions be the same as those supporting learning in children?
In other words, is it possible that adults never stop learning language and simply develop better-calibrated priors? 
In this section, we discuss three possible implications of viewing language acquisition in terms of social coordination and convention formation, which may help to further unify models of adult communication with those of language learning \cite<e.g.>{XuTenenbaum07_WordLearningBayesian,FrankGoodmanTenenbaum09_Wurwur,bohn2019pervasive}.

First, developmental paradigms have typically focused on variability and generalization across referential contexts (e.g. in cross-situational word learning) rather than variability and generalization across speakers  \cite{siskind1996computational,regier2005emergence,smith2014unrealized,yurovsky2015integrative}. 
Yet it is increasingly apparent that children are able to track \emph{who} produced the words they are learning and use this information when generalizing.
For example, bilingual children learn to expect different languages to be used by different speakers and even infants are sensitive to coarse social distinctions based on foreign vs. native language \cite{KinzlerDupouxSpelke07_LanguageGroups}, or accent \cite{KinzlerEtAl09_AccentRace}. 
Children are also sensitive to the reliability of individual speakers. 
For example, young children may limit the generalizability of observations from speakers who use language in idiosyncratic ways, such as a speaker who calls a ball a ``dog'' \cite{koenig2010sensitivity,luchkina2018eighteen}, and may even retrospectively update their beliefs about earlier evidence from a speaker after observing such idiosyncracies \cite{dautriche2021}. 
Such discounting of idiosyncratic speakers may be understood as an instance of the same inductive problem that convention formation poses for adults in \textbf{P2}.
Unlike complete-pooling models, which predict that all observations should be equally informative about a community's conventions, CHAI predicts that children should be able to explain away ``outliers'' without their community-level expectations being disrupted.
One novel prediction generated by our account is that children should be able to accommodate idiosyncratic language \emph{within} extended interaction with the same speaker (e.g. continue to pretend the ball is called ``dog,'' given partner-specific common ground) while also limiting generalization of that convention \emph{across} other speakers.

Second, CHAI emphasizes the importance of representing lexical \emph{uncertainty} (\textbf{C1}), capturing expected variability in the population beyond the point estimates assumed by traditional lexical representations. 
But how do children calibrate their lexical uncertainty?
The number of distinct speakers in a child's environment may play a key role, by analogy to the literature on talker variability \cite{creel2011talker,clopper2004effects}.
Exposure to fewer partners may result in weaker  or mis-calibrated priors \cite<e.g.>{lev2017talking}.
If an idiosyncratic construction is over-represented in the child's environment, they may later be surprised to find that it was specific to their household's lexicon and not shared by the broader community  \cite<see>[Chap. 6]{Clark09_FirstLanguageAcquisition}. 
Conversely, however, hierarchical inference predicts a blessing of abstraction \cite{GoodmanUllmanTenenbaum11_TheoryOfCausality}: under certain conditions, reliable community-level conventions may be inferred even with relatively  sparse observations from each partner.
To resolve these questions, future work will need to develop new methods for eliciting children's expectations about partner-specificity and variability of meanings.

Third, our work suggests a new explanation for why young children struggle to coordinate \emph{ad hoc} conventions with one another in repeated reference games \cite{GlucksbergKraussWeisberg66_DevoRefGames,KraussGlucksberg69_DevoReferenceGames,KraussGlucksberg77_SocialNonsocialSpeech,matthews2007toddlers}. 
Early explanations appealed to rigidity in the child's perspective that prevented adaptation.
Yet subsequent findings that children could not even interpret their own utterances after a delay \cite{asher1976children} suggest that the challenge may instead stem from production quality and the lack of coordinating 'signal'. 
Children may either be unable to anticipate how much information is required for their partner to discriminate the referent, or struggle to access those more complex formulations. 
In terms of our model, children's lexical priors may be weaker than adults': without existing conventions for describing the novel objects in their vocabulary, their utterances are dispersed widely over easier-to-access ``good-enough'' formulations \cite{goldberg2019explain}.
Indeed, when children are paired with their caregivers rather than peers, they easily coordinate on new conventions \cite{LeungEtAl20_Pacts}.
Adults helped to interactively scaffold the conventions, both by proactively seeking clarification and providing strong feedback in the listener role \cite<e.g.>{anderson1994interactive} and by providing more descriptive labels in the speaker role, which children immediately adopted\footnote{It may be observed that agents in our simulations were still able to quickly coordinate despite being initialized with weak priors, but they had the benefit of using feedback from the referential task, as well as small, shared vocabularies. In the paradigms used by \citeA{KraussGlucksberg69_DevoReferenceGames}, young children did not have access to such information and may have struggled to search their vocabulary for better candidates even if they did, especially under time pressure \cite<e.g.>{glucksberg1967people}. This kind of accessibility consideration has previously been instantiated in computational models via the cost term $c(u)$, but further work on convention formation in developmental samples may benefit from a more fine-grained, process model of production.}.
From this perspective, \emph{ad hoc} conventions may not be so different from other settings where children look to their parents for guidance and rapidly adopt new conventions to talk about new things \cite<e.g.>{carey1978acquiring,heibeck1987word}. 

%While we have highlighted three particular developmental phenomena where our approach may generate novel predictions, there are many finer-grained questions raised by our computational approach.
%For example, is the child's lexical expectations in communication best explained as a (resource-limited) representation of \emph{others'} lexicons, or as an egocentric (asocial) epistemic state? 
%To what extent is the ability to retrieve or use this lexical prior constrained by theory of mind development? 

\subsection{The role of communication modality}

One of our core claims is that the basic learning mechanisms underlying coordination and convention formation are domain-general.
In other words, we predict that there is nothing inherently special about spoken or written language: any system that humans use to communicate should display similar \emph{ad hoc} convention formation dynamics because in every case people will be trying to infer the system of meaning being used by their partners. 
Directly comparing behavior in repeated reference games across different modalities is therefore necessary to determine which adaptation effects, if any, are robust and attributable to modality-general mechanisms.
In fact, there has been significant progress in understanding the dynamics of adaptation during communication in the  graphical modality \cite{GarrodFayLeeOberlanderMacLeod07_GraphicalSymbolSystems,TheisenEtAl10_SystematicityArbitrariness,hawkins2019disentangling}, the gestural modality \cite{FayListerEllisonGoldinMeadow13_GestureBeatsVocalization,motamedi2019evolving,bohn2019young} and other \emph{de novo} modalities \cite{Galantucci05_EmergenceOfCommunication,RobertsGalantucci12_DualityOfPatterning,RobertsEtAl15_IconocityOnCombinatoriality,VerhoefRobertsDingemanse15_Iconicity,VerhoefEtAl16_TemporalLanguage,kempe2019adults}.

CHAI views the similarities and differences between modalities through the lens of the hierarchical \emph{priors} we have built up across interactions with different individuals.
For example, in the verbal modality, the tangram shapes from \citeA{ClarkWilkesGibbs86_ReferringCollaborative} are highly ``innominate'' \cite<meaning empirically difficult to name;>{HupetEtAl91_CodabilityReference,zettersten2020finding} -- most people do not have much experience naming or describing them with words, so relevant priors are weak and local adaptation plays a greater role.
In the graphical modality, where communication takes place by drawing on a shared sketchpad, people can be expected to have a stronger prior rooted in assumptions about shared perceptual systems and visual similarity \cite{fan2018common}.
Drawing a quick sketch of the tangram's outline may suffice for understanding.
Other referents have precisely the opposite property: to distinguish between natural images of dogs, people may have strong existing conventions in the linguistic modality (e.g. `husky', `poodle', `pug') but making the necessarily fine-grained visual distinctions in the graphical modality may be initially very costly for novices \cite{fan2020pragmatic}, requiring the formation of local conventions to achieve understanding \cite{hawkins2019disentangling}. 
The gestural modality also has its own distinctive prior, which also allows communicators to use time and the space around them to convey mimetic or depictive meanings that may be difficult to encode verbally or graphically \cite{goldin-meadow_role_1999,clark2016depicting,mcneill1992hand}. 
We therefore suggest that differences in production and comprehension across modalities may be understood by coupling modality-specific priors with modality-generic learning mechanisms.

%If we adhered solely to the verbal modality, we would be limited to a fairly narrow range of stimuli (e.g. abstract shapes/tangrams) where behavior in the lab isn't totally dominated by strong prior conventions people bring into the interaction. 
%For example, similar phenomena Pictionary games where participants use a whiteboard to draw messages instead of an auditory or text-based channel \cite{GarrodFayLeeOberlanderMacLeod07_GraphicalSymbolSystems,TheisenEtAl10_SystematicityArbitrariness,hawkins2019disentangling}.

%Another modality-based manipulation is to attempt to destroy or scramble any meaningful priors that people might carry into the social interaction.
%For example, \citeA{Galantucci05_EmergenceOfCommunication} introduced a novel `seismograph' interface for communication -- a stylus that could be moved side-to-side or lifted up or down to make contact with the sketch pad while the vertical dimension drifted downward at a constant rate.
%The resulting messages consequently look nothing like the usual kinds of symbols people create: the relationship between motor actions and perceptual output is broken such that executing a familiar movement for a symbol or numeral instead produces an odd, wavy scribble.
%Despite the relative lack of priors on signal meanings in this medium, people were nevertheless able to converge on successful signaling systems in repeated reference games \cite<see also>{RobertsGalantucci12_DualityOfPatterning,RobertsEtAl15_IconocityOnCombinatoriality}.
%Other novel modalities used in iterated reference games include a `whistle' language where movements along a vertical touch bar slider correspond to changes in pitch \cite{VerhoefRobertsDingemanse15_Iconicity} and a visual analog where movements along the slider were presented visually \cite{VerhoefEtAl16_TemporalLanguage}.
%
%\subsection{The role of feedback and backchannels}
%\todo[]{(I'm pretty sure direct feedback isn't needed for reduction in general:  notice we initially introduce a new individual into the discourse with a name or description, but  we subsequently simply use a pronoun (shorter) or omit -- we don't need feedback to do this. This is a section that I'd consider omitting as the type of feedback that's provided here is pretty specific to this game; you're also citing quite old literature here, so its less newsworthy and the idea that we don't reduce partially for ourselves is less convincing than other parts of the paper }
%
%If convention formation is grounded in inference, then an important corollary of our model is that the extent to which partners are able to coordinate should depend critically on the observations $D_i$ they condition on in Eq.~\ref{eq:joint_inference}.
%In the \emph{complete} absence of feedback --- when the speaker is instructed to repeatedly refer to a set of objects for a listener who is not present and will do their half of the task offline --- there is no reduction in message length \citeA{HupetChantraine92_CollaborationOrRepitition}. 
%
%Our simulations examined the most minimal sources of feedback: the speaker's utterance and the listener's response in a reference game.
%A key direction for future work is to account for richer forms of feedback that arise in natural communication.
%For example, a key feature of dialogue is the capacity for a \emph{real-time back-channel}.
%The listener may say anything at any point in time, thus allowing for interjections (uh-huh, hmmm, huh?), clarification questions, and other listener-initiated forms of feedback. 
%Elaborating the generative model of the listener to include these verbal behaviors will be critical to explaining other key results from \citeA{ClarkWilkesGibbs86_ReferringCollaborative}, including changes in the frequency of listener-initiated feedback over the course of interaction.
%
%Additionally, such an elaboration would allow our model to address early empirical results from \citeA{KraussWeinheimer66_Tangrams} manipulating the feedback channel: participants were able to talk bidirectionally in one condition but in another condition, the channel was unidirectional. 
%The speaker was prevented from hearing the listener's responses. 
%This feedback manipulation was crossed with a behavioral feedback manipulation where the experimenters intercepted the listener's responses: one group of speakers was told that their partner made the correct response 100\% of the trials (regardless of their real responses), while another was told on half of the trials that their partner made the incorrect response. 
%Our account of increasing efficiency (\textbf{P1}) predicts that speaker may not have sufficient evidence to justify shorter utterances in the absence of evidence about how their longer descriptions are being interpreted.
%Indeed, \citeA{KraussWeinheimer66_Tangrams} found that both channels contribute independently to gains in efficiency.
%Speakers kept using longer utterances when they observed that their partner was making errors. 
%But blocking the real-time verbal back-channel significantly limited reduction, even when told that their partner was achieving perfect accuracy.
%%Speakers converged to utterances that were about twice as long as those found when verbal feedback was allowed.
%In the extreme case of trying to communicate to a listener who can't respond and also appears to not understand, speaker utterance length actually \emph{increased} with repetition after an early dip. 
%
%More graded disruptions of feedback seem to force the speaker to use more words overall but not to significantly change the rate of reduction. 
%For example, \citeA{KraussBricker67_Delay} tested a transmission delay to temporally shift feedback and an access delay to block the onset of listener feedback until the speaker is finished. 
%Later, \citeA{KraussEtAl77_AudioVisualBackChannel} replicated the adverse effect of delay but showed that undelayed visual access to one's partner cancelled out the effect and returned the number of words used to baseline. 
%On the listener's part, too, the ability to actively \emph{give} feedback appears critical for coordination. 
%\citeA{SchoberClark89_Overhearers} showed that even listeners who \emph{overheard} the entire game were significantly less accurate than listeners who could directly interact with the speaker, even though they heard the exact same utterances, presumably because the speaker was not able to take their particular sources of confusion into account.
%Our model provides a formal framework to begin probing how these different forms of communicative feedback may license different inferences about one's partner in interaction.

%\subsection{The role of social knowledge}
%\adele{You focus on \textit{new} referring expressions, but I wonder if you could extend to existing expressions too by thinking about the role of frequency/entrenchment.

%\todo[]{this isn't a todo at all, but I bet the same uncertainty and generalization with evidence of broader use is relevant to contexts as well as individuals: if you order a 'cup of coffee' in Italy, you may get espresso; we can change our conventions even with the same people in  different contexts: individuals (especially unusual individuals) provide a clear indication of context}

%  1) A reviewer asks whether common ground or authority is most relevant: I think that difference determines how far a new expression is likely to spread. Random groups of speakers don't get to name things that are relevant to most speakers of a language:  (typically?) a small group of visible &/or respected people name the new thing and the rest of us go along with that term pretty quickly,reducing when they reduce. To your point, we may still alternate with a longer phrases esp when there's lack of common ground: 'Jan 6th insurrection' 'COVID19', 'the Delta variant'). T

% 2) For terms we already have a referring expression for, we often resist  change so if it occurs at all, it'd be on a  much slower time scale: probably because the term is too entrenched for us to bother bringing it to a larger group, or perhaps when we feel it reflects our membership in a group (see hoagie/sub; on line/in line; shore/beach; 

% --> Authority (sometimes localized sometimes diffuse) and prior FREQUENCY/entrenchment play a role in how likely a speaker is to adapt and so how likely or quickly a change in the language is (associations surely predict this).

%\todo[]{(I'd also consider eliminating this section if you want to simplify the general discussion, for similar reasons; the model doesn't include social information beyond identity. Down the line it'd be useful to use this sort of hierarchical grouping or even better, potentially dynamic clustering depending on contexts, to account for why some words are limited to specific contexts as well as specific people: e.g, Thing 1 and Thing 2 are associated with Dr. Suess books, subway with NY; BART with Bay Area.)}
%Real-world communities are much more complex than the simple networks we considered: each speaker takes part in a number of overlapping subcommunities, and may be more centrally or peripherally involved with stronger or less strong priors in each. 
%For example, we use partially distinct conventions depending on whether we are communicating with psychologists, friends from high school, bilinguals, or children \cite{auer_code-switching_2013}.
%When a scientist is talking to other scientists about their work, they know they can use efficient technical shorthand that they would avoid when talking to their non-expert friends and family. 
%Previous work has probed representations of community membership by manipulating the extent to which cultural background is shared between speaker and listener.
%For example, \citeA{IsaacsClark87_ReferencesExpertsNovices} paired participants who had either lived in NYC or had never been there for a task referring to landmarks in the city (e.g. ``Rockefeller Center''). 
%Within just a few utterances from a novel partner, people could infer whether they were playing with an expert or novice and immediately adjust their language use to be appropriate for this inferred identity. 
%Social information about a partner’s group can be so important that even players in artificial-language games react to the restrictions of social anonymity by learning to identify members of their community using distinctive signals \cite{roberts_experimental_2010}.

%For future work using hierarchical Bayesian models to address the full scale of an individual's  network of communities, additional social knowledge about these communities must be learned and represented in the generative model.
%Larger-scale networked experiments can be used to evaluate the hypothesis that a hierarchical representation of conventions includes not just a partner-specific level and population-wide level but also intermediate community levels. 
%This hypothesis can be formalized by including additional latent representations of community membership into our hierarchical model.
%That is, in addition to updating our model of a particular \emph{partner} based on immediate feedback, even sparse observations of a partner's language use may license much broader inferences about their lexicon via diagnostic information about their social group or background. 
%If someone's favorite song is an obscure B-side from an 80s hardcore band, you can make fairly strong inferences about what else they like to listen to and how similar they might be to you \cite{VelezEtAl16_Overlaps, GershmanEtAl17_StructureSocialInfluence}. 
%Similarly, if someone casually refers to an obscure New York landmark, you may be able to update your beliefs not just about that lexical item but about a number of other lexical conventions shared among New Yorkers. 
%Lexica cluster within social groups, so inverting this relationship can yield rapid lexical learning from inferences about social group membership.

%This explanation is also consistent with broader linguistic phenomena outside the realm of repeated reference games. 
%For example, \citeA{PottsLevy15_Or} showed that lexical uncertainty is critical for capturing constructions like \emph{oenophile or wine lover}, where a disjunction of synonymous terms is taken to convey a definition -- information about the speaker's lexicon -- rather than a disjoint set. 
%While the reasons that speakers produce such constructions are complex, we would expect that speakers will be more likely to produce the definitional \emph{or} when the component word is expected to be rarer or more obscure for a particular partner: when there is additional uncertainty over its likely meaning in the listener's lexicon.


\subsection{Process-level mechanisms for adaptation}

Finally, while we have provided a computational-level account of coordination and convention formation in terms of hierarchical inference, there remain many possible process-level mechanisms that may perform this computation.
In this section, we discuss two interlocking process-level questions which emphasize current limitations and areas of future work: (1) exactly which representations should be adapted? and (2) what is required to scale models of adaptation to more naturalistic language? 

\subsubsection{Which representations are adapted?}

While our model formulation focused on adaptation at the level of lexical meaning (i.e. inferences about $\phi$, representing different possible lexical meanings), this is only one of many internal representations that may need to be adapted to achieve successful coordination. 
Three other possible representational bases have been explored in the literature. 

First, it is possible that adaptation takes place upstream of the lexicon, directly implicating perceptual or \emph{conceptual} representations \cite{GarrodAnderson87_SayingWhatYouMean,HealeySwobodaUmataKing07_GraphicalLanguageGames}
That is, there may be uncertainty about how a particular partner construes the referent itself, and communication may require constructing a shared, low-dimensional conceptual space where the relevant referents can be embedded \cite{stolk2016conceptual}.
This is particularly clear in the classic maze task \cite{GarrodAnderson87_SayingWhatYouMean} where giving effective spatial directions requires speakers to coordinate on what spatial representations to use (e.g. paths, coordinates, lines, or landmarks). 

Second, it is possible that adaptation takes place even further upstream, at the level of \emph{social} representations \cite{jaech2018low}.
Rather than directly updating beliefs about lexical or conceptual representations, we may update a holistic representation of the partner themselves (e.g. as a ``partner embedding'' in a low-dimensional vector space) that is used to retrieve downstream conceptual and lexical representations. 
Under this representational scheme, the mapping from the social representation to particular conventions is static, and \emph{ad hoc} adaptation is limited to learning where a particular partner belongs in the overall social space.

Third, expectations about other lower-level features may also be adapted through interaction, such as a partner's word frequencies \cite{louwerse2012behavior}, syntax \cite{gruberg2019syntactic,levelt1982surface}, body postures \cite{lakin2003using}, speech rate \cite{giles1991contexts}, or even informational complexity \cite{abney2014complexity}.
This level of adaptation may lead some forms to become more accessible or entrenched in memory over time, possibly allowing partner identity to be used as a retrieval cue (e.g. \citeNP{horton2005impact,horton2007influence,horton_revisiting_2016}; but see \cite{brown2014influence}).

\subsubsection{Computational tractability and scalability}

While a fully Bayesian formulation elegantly formalizes the computational-level inference problem at the core of the CHAI account, this formulation faces a number of limitations. 
For one, it is clearly intractable \cite{van2008tractable,van2019cognition}: the posterior update step in Eq.~\ref{eq:joint_inference} grows increasingly intensive as the space of possible utterances and meanings grows \cite{scalingupmodels}.
The intractability problem also raises a scalability problem: does CHAI provide any guidance toward building artificial agents that are actually able to adapt to human partners as humans do with one another?
Through this applied lens, a number of recent efforts have focused on developing algorithms for state-of-the-art neural networks that tractably scale to arbitrary natural language (e.g. referring expressions using the full vocabulary of an adult language user) and arbitrary visual input (e.g. sensory impressions of novel objects such as tangrams).

For example, building on recent formal connections between hierarchical Bayes and gradient-based meta-learning approaches in machine learning \cite{grant_recasting_2018}, the algorithm proposed by \citeA{hawkins2019continual} (1) relaxes the full community-level prior over $\Theta$ to a point estimate and (2) replaces the difficult integral in the posterior update with a fixed number of (regularized) gradient update steps.
While such approximate algorithms cannot fix the intractability of the Bayesian formulation \cite{kwisthout2011bayesian}, and their precise correspondence to constraints on the computational-level theory remain unexplored, they nonetheless provide a promising algorithmic instantiation of the CHAI principles. 
When lexical meaning is represented by the parameters of a neural network, conventions can be interpreted as learned \emph{initializations} used for new partners and coordination is partner-specific \emph{fine-tuning} or \emph{domain adaptation} of vector representations. 

Neural network instantiations also provide a possible pathway toward addressing the lack of incrementality in the fully Bayesian formulation. 
As more scalable implementations of pragmatic reasoning have proliferated in machine learning \cite{vogel2013emergence,AndreasKlein16_Pragmatics,monroe_colors_2017,shen2019pragmatically,takmaz2020refer} it has been natural to use incremental architectures  \cite{augurzky2019gricean,cohn2018pragmatically,cohn2019incremental,waldon2021modeling}. 
However, there remain a number of limitations to address in future work, including how to incorporate incremental \emph{feedback} into lexical updates (e.g. backchannel responses or interruptions), how to define a more satisfying notion of \emph{compositional semantics} for incrementally constructed utterances, and how to maintain representations of partner-specific parameters alongside community-wide parameters in memory. 

%The first computational obstacle is the lexical representation.
%A discrete $m\times n$ matrix containing entries for each utterance-referent pair, as typically used in convention formation simulations, has two primary limitations as a proxy for human representations: (1) it  grows quadratically as additional utterances and referents are added while becoming increasingly sparse (i.e. most words only apply to a relatively small set of referents) and (2) it does not straightforwardly represent similarity relationships between utterances and referents (i.e. a new referent must be added as a distinct new column, even if it is visually similar to a known referent).
%This limitation is especially clear when referents are presented as raw images. 
%
%The second computational obstacle is the inference algorithm.
%Even if a more scalable family of lexical representations $\mathcal{L}_\phi$ is chosen, any parameterization $\phi$ of this representation will be much higher-dimensional than we have considered.
%For example, if $(\Theta, \phi)$ are defined to be the weights of a neural network, then maintaining uncertainty $P(\Theta, \phi)$ would require placing a prior over the weights and the posterior update $P(\Theta, \phi | D)$ would require a difficult integral over a very high-dimensional support, or a type of (hierarchical) Bayesian neural network \cite{mackay1992practical,neal2012bayesian}.
%While recent algorithmic breakthroughs have made (approximate) inference for such networks increasingly tractable \cite<e.g.>{hernandez2015probabilistic,lacoste2018uncertainty,dusenberry2020efficient,izmailov2020subspace}, they remain untested as cognitive models.
%


\paragraph{Conclusion}

How do we manage to understand one another?
We have argued that successful communication depends not just on transmission but on continual learning across multiple timescales. 
We must coordinate on meaning through common ground with individual partners but also abstract these experiences away to represent stable \emph{conventions} and norms that generalize across our communities.
Like other socially-grounded knowledge, language is not a rigid dictionary that we acquire at an early age and deploy mechanically for the rest of our lives. 
Nor do languages only change over the slow time-scales of inter-generational drift.
Language is a means for communication -- a shared interface between minds -- and as new \emph{ad hoc} concepts arise, new \emph{ad hoc} conventions must be formed to solve the new coordination problems they pose.
In other words, we are constantly learning language. 
Not just one language, but a family of related languages, across interactions with each partner. 

\begin{quote}
\emph{Let us conclude not that ‘there is no such thing as a language’ that we bring to interaction with others. Say rather that there is no such thing as the one total language that we bring. We bring numerous only loosely connected languages from the loosely connected communities that we inhabit.} \cite{hacking1986nice}
\end{quote}
