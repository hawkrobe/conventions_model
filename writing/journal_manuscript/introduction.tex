
% 4 paragraph intro

To communicate successfully, speakers and listeners must share a common system of semantic meaning in the language they are using. 
These meanings are \emph{conventional} in the sense that they are sustained by stable prior expectations each person has about others, even complete strangers \cite{lewis_convention:_1969, hawkins2019emergence}.
At the same time, meaning is remarkably flexible and \emph{partner-specific} \cite{clark_using_1996}.
The same word may be interpreted differently by different listeners, and may take on new \emph{ad hoc} senses over the course of a single conversation. 

The tension between these two notions of meaning has been typically been resolved by emphasizing one over the other.
Theories of how communities reach consensus on shared conventions exclude any notion of partner-specific meaning \cite{Steels}.
Meanwhile, theories that have grappled with \emph{partner-specific} meaning have taken the equally radical step of banishing shared conventions.
The philosopher Donald Davidson called the former, conventional notion of meaning a \emph{prior theory} and the latter, partner-specific notion a \emph{passing theory}. 
According to Davidson, it is the passing theory that is responsible for successful communication, since no two prior theories will be exactly alike: in fact, ``there is no such thing as a language'' \cite[p. 174]{davidson_nice_1986}.

In this paper, we present a theory of convention formation that establishes a bi-directional relationship reconciling the stability of a community's conventions with the ability to rapidly coordinate on \emph{ad hoc} meanings. 
This 

\subsection{Reduction}

If our lexical priors -- our global conventions -- serve as a source of stability in meaning over longer timescales, then what accounts for our extraordinary flexibility  over short timescales? How do we coordinate on efficient local conventions, or \emph{conceptual pacts}, for talking about things we've never talked about before? In this section, we review the dynamics of coordination within repeated reference games and explore the possibility, formalized in Chapter 2, that rapid adaptation can be understood in a Bayesian modeling framework as lexical inference given partner-specific data.%: $P(\mathcal{L}_i | D_i, \Theta)$. 

The most well-known phenomenon in repeated reference games is a reduction in message length over multiple rounds. 
\citeA{KraussWeinheimer64_ReferencePhrases} were the first to report this phenomenon in a short technical report introducing the repeated reference game paradigm, and it has been replicated many times under many conditions \cite<most notably by>[in a much more streamlined experimental design using tangram shapes]{ClarkWilkesGibbs86_ReferringCollaborative}. 
The core descriptive result was that, taken in aggregate, frequently mentioned targets tend to be labeled using shorter phrases than infrequently mentioned targets, thus reproducing Zipf's law within the microcosm of a single conversation. To explain the process by which such a distribution emerges, they reasoned that labels may change with repeated use over the course of interaction. Indeed, the first time participants referred to a figure, they used a lengthy, detailed description (``the upside-down martini glass in a wire stand'') but with a small number of repetitions -- between 3 to 6 times, depending on the pair -- the description was reduced down to the limit of just one or two words (``martini''). 

Note that although initial messages are just as long or longer than the other-intended messages collected by \citeA{FussellKrauss89_IntendedAudienceCommonGround}, final messages are as short or shorter than the one-shot messages intended for \emph{oneself}. Furthermore, final messages are often incomprehensible to overhearers who were not present for the initial messages \cite{SchoberClark89_Overhearers}. This observation sets up the central empirical puzzle of convention formation: how does a short word or phrase that would have been completely ineffective for communicating under the initial lexical prior become perfectly understandable over mere minutes of interaction? What changes inside participants' minds in the interim? 

One simple non-social explanation --- that reduction is merely an effect of familiarity or repetition on the part of the speaker --- can be easily dispelled. 
When participants are asked to repeatedly refer to the same targets for a hypothetical partner, no reduction is found, and in some cases utterances actually get longer \cite{HupetChantraine92_CollaborationOrRepitition}. 
Whatever is changing must be a result of the \emph{interaction} between partners. An alternative explanation suggested by our probabilistic model is that reduction is driven by lexical learning as communication partners coordinate on ad hoc names. 
If long initial messages can be explained as the result of initial uncertainty in the lexical prior, as discussed in the previous section, then a decrease in uncertainty licenses shorter messages \cite{HawkinsFrankGoodman17_ConventionFormation}. 

\subsection{Signatures of reduction}

What are empirical cues to this reduction in uncertainty? The first is the use of \emph{hedges}. Hedges are expressions like \emph{sort of} or \emph{like}, and morphemes like \emph{-ish}, that explicitly mark uncertainty or provisionality, such as \emph{a car, sort of silvery purple colored} \cite{BrennanClark96_ConceptualPactsConversation,Fraser10_Hedging,MedlockBriscoe07_HedgeClassification}. If participants reduce their lexical uncertainty over successive rounds, then we might expect a corresponding decrease in explicit markers of this uncertainty. \citeA{BrennanClark96_ConceptualPactsConversation} counted hedges over four repetitions of an initially ambiguous target and found widespread use of \emph{hedges} on the first round (occurring 26\% of messages) but almost complete absence on the last (only 2\% of messages). They also found very few initial hedges for targets with low initial uncertainty (e.g. a shoe in the context of dogs and fish), providing additional evidence for the role of \emph{lexical} uncertainty as opposed to a generic social use of hedges.

Another characteristic of uncertainty reduction lies in \emph{what} gets reduced \cite{hawkins2020characterizing}.
Is the speaker adopting a fragment shorthand by randomly dropping function words, or are they simplifying or narrowing their descriptions to names by omitting redundant details? Closed-class parts of speech like determiners and prepositions \emph{are} much more likely to be dropped than open-class parts of speech like adjectives and nouns. But when we examine broader grammatical units using recent NLP techniques, we find that entire modifying clauses are increasingly likely to be dropped \cite{HawkinsFrankGoodman17_ConventionFormation}. This accords with early hand-tagged analyses by \citeA{Carroll80_NamingHedges}, which found that in three-quarters of transcripts from \citeA{KraussWeinheimer64_ReferencePhrases} the short names that participants converged upon were prominent in some syntactic construction at the beginning, often as a head noun that was initially modified or qualified by other information. 
These more fine-grained analyses suggest that reduction is grounded in the prior lexical content of the interaction and the speaker's increasing confidence in how the listener will interpret an initially ambiguous label. Like the evidence we reviewed about lexical priors, however, this evidence remains indirect and raises the need for more careful, direct measurement of lexical uncertainty over interaction. 

\subsection{Quality of feedback}

If adaptation is learning, then the extent to which partners adapt should depend critically on the quality of the data $D_i$ on which they are conditioning: $P(\mathcal{L}_i | \Theta, D_i)$. In the absence of additional cues to the meanings that their partner is using to interpret their messages, a speaker or drawer can only continue to rely on their prior, or indeed elaborate upon it. A common feature of the reference games reviewed so far is the capacity for \emph{real-time feedback channel}: either player may say anything at any point in time, thus allowing for interruptions, back-channel responses (uh-huh, hmmm, huh?), clarification questions, and so on. To what extent is this design choice necessary for reduction? \citeA{KraussWeinheimer66_Tangrams} were the earliest to address this question by manipulating the kind of feedback received by the speaker.

In one condition, participants were able to talk freely and bidirectionally as in \citeA{KraussWeinheimer64_ReferencePhrases}; in another condition, the channel was unidirectional: the speaker was unable to hear the listener's responses. This real-time feedback manipulation was crossed with a behavioral feedback manipulation where the experimenters intercepted the listener's responses: one group of speakers was told that their partner made the correct response 100\% of the trials (regardless of their real responses), while another was told on half of the trials that their partner made the incorrect response. 

Intuitively, we might expect that if the speaker is unsure how their longer descriptions are being interpreted -- unsure whether or not they can get away with shorter, more ambiguous expressions -- they may not have enough evidence about meanings to justify shorter utterances. Indeed, \citeA{KraussWeinheimer66_Tangrams} found that even when told that their partner was getting 100\% correct, entirely blocking the verbal feedback channel significantly limited the reduction effect. Speakers converged to utterances that were about twice as long -- twice as inefficient -- in the limit. Telling speakers that their partner was performing poorly also inhibited reduction as a main effect, though to a lesser extent. In the extreme case of trying to communicate to a listener who can't respond and appears to not understand, speaker utterance length actually increased with repetition after an early dip. \citeA{HupetChantraine92_CollaborationOrRepitition} later found that in the \emph{complete} absence of feedback --- when the speaker is instructed to repeatedly refer to a set of objects for a listener who is not present and will do their half of the task offline --- there is also no reduction in message length. On the listener's part, too, the ability to actively \emph{give} feedback appears critical for learning. \citeA{SchoberClark89_Overhearers} showed that listeners who overheard the entire game were significantly less accurate than listeners who could directly interact with the speaker, even though they heard the exact same utterances.

More graded disruptions of feedback seem to force the speaker to use more words overall but not to significantly change the rate of reduction (though rigorous comparisons between rates have not been conducted). For example, \citeA{KraussBricker67_Delay} tested a transmission delay to temporally shift feedback and an access delay to block the onset of listener feedback until the speaker is finished. Later, \citeA{KraussEtAl77_AudioVisualBackChannel} replicated the adverse effect of delay but showed that undelayed visual access to one's partner cancelled out the effect and returned the number of words used to baseline. 

\paragraph{Context-sensitivity}

\paragraph{Generalization}

A key property of linguistic conventions is that they hold over an entire community of speakers, allowing us to communicate efficiently even with people we've never met before.
But exactly how do we make the inferential leap to community-wide expectations from our experiences with specific partners? 
Grounding collective convention formation in individual cognition requires an explicit *theory of generalization* capturing how people transfer what they have learned from one partner to the next.

One influential theory is that speakers simply ignore the identity of different partners and update a single monolithic representation after every interaction \cite{steels_self-organizing_1995,barr_establishing_2004,young_evolution_2015}.
We call this a *complete-pooling* theory because data from each partner is collapsed into an undifferentiated pool of evidence \cite{gelman2006data}. 
Complete-pooling models have been remarkably successful at predicting collective behavior on networks, but have typically been evaluated only in settings where anonymity is enforced. 
For example, \citeA{centola_spontaneous_2015} asked how large networks of participants coordinated on conventional names for novel faces.
On each trial, participants were paired with a random neighbor but were not informed of that neighbor's identity, or the total number of different possible neighbors. 

While complete-pooling may be appropriate for some everyday social interactions, such as coordinating with anonymous drivers on the highway, it is less tenable for everyday communicative settings.
Knowledge about a partner's identity is both available and relevant for conversation \cite{eckert_three_2012, davidson_nice_1986}.
Extensive evidence from psycholinguistics has demonstrated the *partner-specificity* of our language use \cite{clark_using_1996}.
Because meaning is grounded in the evolving 'common ground' shared with each partner, meanings established over a history of interaction with one partner are not necessarily transferred to other partners \cite{wilkes-gibbs_coordinating_1992,metzing_when_2003}.
Partner-specificity thus poses clear problems for complete-pooling theories but can be easily explained by another simple model, where agents maintain separate expectations about meaning for each partner.
We call this a \emph{no-pooling} model.
The problem with no-pooling is that agents are forced to start from scratch with each partner.
Community-level expectations never get off the ground.

What theory of generalization, then, can explain partner-specific meaning but also allow conventions to spread through communities?
We propose a \emph{partial-pooling} account that offers a compromise between these extremes.
Unlike complete-pooling and no-pooling models, we propose that beliefs about meaning have hierarchical structure.
That is, the meanings used by different partners are expected to be drawn from a shared community-wide distribution but are also allowed to differ from one another in systematic, partner-specific ways.
This structure provides an inductive pathway for abstract population-level expectations to be distilled from partner-specific experience.
Hierarchical models have been key to explaining how the human mind solves other difficult inductive problems in domains like causal learning \cite{KempGoodmanTenenbaum10_LearningToLearn,GoodmanUllmanTenenbaum11_TheoryOfCausality}, speech perception \cite{KleinschmidtJaeger15_RobustSpeechPerception} and concept learning \cite{KempPerforsTenenbaum07_HBM, tenenbaum_how_2011} where abstract, shared properties must be jointly inferred with idiosyncratic particulars of instances.


\subsection{Theoretical approaches to convention formation}

%
%\subsection{Cognitive theories of local alignment}
%
%Interactive alignment theories say that coordination is `priming' with some connectionist voodoo that trickles up levels. 
%
%\subsection{Distributed network theories of global convergence}
%
%Agent-based models use heuristics 
%
