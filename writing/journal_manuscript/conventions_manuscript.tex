\documentclass[11pt, floatsintext]{apa6}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[outdir=./]{epstopdf}
%\DeclareGraphicsExtensions{.eps}
\usepackage{caption}
\captionsetup{font=footnotesize}

\usepackage{mathtools}
\usepackage{enumerate}
\usepackage{textcomp}
\usepackage{lingmacros}
\usepackage[draft]{hyperref}
\usepackage{apacite}
\usepackage{listings}
\usepackage{multirow}
\usepackage{stfloats}
\usepackage{todonotes}
\usepackage{svg}
\usepackage{booktabs}
\usepackage{stmaryrd}

\synctex=1
\usepackage{soul}

\newcommand{\den}[1]{\ensuremath{\llbracket #1 \rrbracket}}

\newcommand{\KL}[2]{\ensuremath{D_{KL}({#1}\, \| \, {#2})}}
\newcommand{\E}[2]{\ensuremath{\mathbb{E}_{#1}\left [#2 \right]}}

\newenvironment{figurehere}
	{\def\@captype{figure}}
	{}

\usepackage{lipsum}
%\pagenumbering{gobble}
%\usepackage{apacite}

\linespread{1}


\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}
\graphicspath{{./figures/}}
 
 \definecolor{Green}{RGB}{10,200,100}
  \definecolor{Red}{RGB}{200,100,50}
\newcommand{\ks}[1]{\textcolor{Red}{[ks: #1]}}  
\newcommand{\rdh}[1]{\textcolor{Blue}{[rdh: #1]}}  


\makeatother

\title{From partners to populations: \\[.1em] A hierarchical Bayesian account of coordination and convention}
\shorttitle{Conventions}
\author{Various people}
\affiliation{Various Universities}

\abstract{Languages are powerful solutions to the coordination problems that arise between agents \ks{Are you using `agents' to refer to both simulated agents and real people? I haven't seen it used in the latter way, I find it slightly weird - but in this sentence I think you could just ditch everything after ``coordination problems" and not lose any clarity.}.
They provide stable, shared expectations about how the words we say correspond to the beliefs and intentions in our heads. 
Yet we use language in a highly variable and non-stationary social environment, requiring linguistic representations to be flexible. 
Old words are given new partner-specific or context-specific meanings on the fly. 
In this paper, we introduce a hierarchical Bayesian account aiming to reconcile the long-standing tension between these perspectives. 
More specifically, we argue that the central computational problem of communication is not simply transmission, as classical accounts have assumed, but \emph{learning} and \emph{adaptation} over multiple timescales.
Under our account, social conventions are stable priors that have been abstracted from interactions with multiple partners, while rapid learning within interactions allows for the formation of partner- and context-specific common ground.
We present new empirical data alongside simulations showing how our model explains several phenomena that have posed a challenge for previous accounts: (1) the convergence to more efficient referring expressions across repeated interaction with the same partner, (2) the gradual transfer of partner-specific common ground to novel partners, and (3) the influence of context on which conventions eventually form.
%Finally, we discuss several broader consequences of our framework, grounding community-level social conventions in basic individual-level learning mechanisms,  suggests new perspectives on continual language learning beyond development. 
}

\keywords{Keywords TBD}

\authornote{This report is based in part on work presented at the 39th, 40th, and 42nd Conferences of the Cognitive Science Society \cite{hawkins_convention-formation_2017,hawkins_emerging_abstractions_2018,hawkins2020generalizing}. Correspondence should be addressed to Robert D. Hawkins, e-mail: rdhawkins@princeton.edu}

\begin{document}
\maketitle

\begin{quote}
\ks{I'm not sure this is the most helpful place for this quote - you do a much better job of explaining the issues in your own words, I find this quote much less clear and it's got bits in it (prior theories, passing theories that aren't defined. If you want to put the whole thing in maybe a better place is where you quite Davidson again in the intro.} 
%The speaker wants to be understood [...] %, so he intends to speak in such a way that he will be interpreted in a certain way. 
\emph{In order to judge how he will be interpreted, [the speaker] uses his starting theory of interpretation. % interpreter’s readiness to interpret along certain lines. %Central to this picture is what the speaker believes is 
%The speaker does not necessarily speak in such a way as to prompt the interpreter to apply this prior theory; he may deliberately dispose the interpreter to modify his prior theory. But the speaker’s view of the interpreter’s prior theory is not irrelevant to what he says, nor to what he means by his words; it is an important part of what he has to go on if he wants to be understood.
As speaker and interpreter talk, their ``prior'' theories become more alike; so do their ``passing'' theories. 
%The asymptote of agreement and understanding is when passing theories coincide. 
%But the passing theory cannot in general correspond to an interpreter’s linguistic competence. 
Not only does it have its changing list of proper names and gerrymandered vocabulary, but it includes every successful use of any other word or phrase, no matter how far out of the ordinary [...] 
%Every deviation from ordinary usage, as long as it is agreed on for the moment [...] is in the passing theory as a feature of what the words mean on that occasion. 
Such meanings, transient though they may be, are literal. \\-- \citeA{davidson_nice_1986}.}

\end{quote}

\input{Introduction}

\section{Convention formation as\\ Hierarchical Bayesian inference}

\input{ModelOverview}

\section{Phenomenon \#1: \\ \emph{Ad hoc} conventions become more efficient}

\input{Reduction}

\section{Phenomenon \#2: \\ Conventions gradually generalize to new partners in a social network}

\input{Generalization}

\section{Phenomenon \#3: \\ Conventions are shaped by communicative context}

\input{ContextSensitivity}

\section{General Discussion}

\input{Conclusion}

\section{\bf Acknowledgments}
\small

\bibliography{ref}
\bibliographystyle{apacite}

\renewcommand{\thefigure}{A\arabic{figure}}
\renewcommand{\thetable}{A\arabic{table}}
\setcounter{table}{0}
\setcounter{figure}{0}





\begin{table*}[th!]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{}                                   & \textbf{Parameter}                                              & \multicolumn{1}{l}{\textbf{Example parameter settings}}                 \\ \midrule
\multirow{11}{*}{\textbf{Partner design}}    & \multirow{3}{*}{What feedback is provided?}                & - no feedback at all                                                  \\
                                            &                                                                 & - only correct/incorrect                                                   \\
                                            &                                                                 & - real-time responses from partner                                         \\ \cmidrule(l){2-3} 
                                            & \multirow{3}{*}{Are you playing with the same partner?}         & - same partner for whole game                                              \\
                                            &                                                                 & - swap out partners every round                                            \\
                                            &                                                                 & - swap after $k$ rounds                                                    \\ \cmidrule(l){2-3} 
                                            & \multirow{3}{*}{What do you know about your partner?}         & - anonymous stranger                                              \\
                                            &                                                                 & - stranger with perceptual information                                            \\
                                            &                                                                 & - close friend                                                    \\ \cmidrule(l){2-3}                                             
                                            & \multirow{2}{*}{How consistent are roles across repetitions?}   & - consistent director/matcher                                              \\
                                            &                                                                 & - alternate roles each round                                               \\ \midrule
\multirow{7}{*}{\textbf{Stimulus design}}   & \multirow{2}{*}{How familiar are targets?}                      & - very familiar: colors, household objects                                 \\
                                            &                                                                 & - not at all familiar: tangrams, novel line drawings                       \\ \cmidrule(l){2-3} 
                                            & \multirow{2}{*}{How complex are targets?}                       & - very complex: busy visual scenes, clips of music                         \\
                                            &                                                                 & - not at all complex: geometric drawings                                   \\ \cmidrule(l){2-3} 
                                            & \multirow{3}{*}{How consistent are targets across repetitions?} & - exact same image of object                                               \\
                                            &                                                                 & - different pose/view of same object                                       \\
                                            &                                                                 & - different objects from same neighborhood                                 \\ \midrule
\multirow{5}{*}{\textbf{Context design}}    & \multirow{2}{*}{How similar are distractors to the target?}     & - very similar: same basic-level category                                  \\
                                            &                                                                 & - not at all similar: other categories                                     \\ \cmidrule(l){2-3} 
                                            & What is the size of context?                                    & - between 2 and 21                                                         \\ \cmidrule(l){2-3} 
                                            & \multirow{2}{*}{How consistent is context across repetitions?}  & - exact same context each round                                            \\
                                            &                                                                 & - randomized context (sometimes far, sometimes close)                      \\ \midrule
\multirow{3}{*}{\textbf{Repetition design}} & How many repetitions per target?                                & - between 3 and 100                                                        \\ \cmidrule(l){2-3} 
                                            & \multirow{2}{*}{What is spacing between repetitions?}           & - block structure                                                          \\
                                            &                                                                 & - sequential structure with interspersed contexts                          \\ \midrule
\textbf{Modality design}                    & What medium is used for communication?                          & \begin{tabular}[c]{@{}l@{}}- text\\ - audio\\ - gesture\\ - drawing\end{tabular} \\ \bottomrule
\end{tabular}%
}
\caption{\normalfont{Proposed parameterization for repeated reference games, each of which theoretically impacts the formation of conventions.}}
\label{table:parameters}
\end{table*}

\normalsize

\section*{Appendix A: Details of RSA model}

Our setting poses several technical challenges for the Rational Speech Act (RSA) framework.
In this Appendix, we describe these challenges in more detail and justify our choices.

\subsection{Handling degenerate lexicons}

First, when we allow the full space of possible lexicons $\phi$, we must confront degenerate lexicons where an utterance $u$ is literally false of every object in context, i.e. where $\mathcal{L}_\phi(o, u) = 0$ for all $o\in \mathcal{C}$. 
In this case, the normalizing constant in Eq.~\ref{eq:RSA} is zero, and the literal listener distribution is not well-defined.
A similar problem may arise when no utterance in the speaker's repertoire is true of the target, in which case the $S_1$ distribution is not well-defined.

Several solutions to this problem were outlined by \citeA{bergen_pragmatic_2016}.
One of these solutions is to use a `softer' semantics in the literal listener, where a Boolean value of false does not strictly rule out an object but instead assigns a very low numerical score, e.g. 
$$\mathcal{L}_\phi(o,u) = \left\{ \begin{array} {rl} 1 & \textrm{if $o \in $\den{u}$_\phi$} \\ \epsilon & \textrm{o.w.} \end{array}\right.$$
Whenever there is at least one $o\in\mathcal{C}$ where $u$ is true, this formulation assigns negligible listener probability to objects where $u$ is false, but ensures that the normalization constant to is non-zero even when $u$ is false for all objects.

While this solution suffices for one-shot pragmatics under lexical uncertainty, where $\epsilon$ may be calibrated to be appropriately large, it runs into several technical complications in an iterated setting.
First, due to numerical overflow at sufficiently high values of $w_L$ and $w_S$ on later iteration, elements may drop entirely out of the support at higher levels of recursion (e.g. $L_1$), leading the normalization constant to return to zero. 
Second, this `soft' semantics creates unexpected and unintuitive consequences at the level of the pragmatic speaker. 
After renormalization in $L_0$, an utterance $u$ that fails to refer to any object in context is also by definition equally \emph{successful} for all objects (i.e. evaluating to $\epsilon$ for every object), leading to a uniform selection distribution.
Consequently, when $S_1$ reasons about this listener, an utterance that is literally false of every object may ultimately be preferred over some utterances which are true.

Instead of injecting $\epsilon$ into the lexical meaning, we ensure that the normalization constant is well-defined by adapting another method suggested by \citeA{bergen_pragmatic_2016}.
First, we add a `null' object to every context so that, even when a particular utterance is false of every real object in context, it will still apply to the null object, assigning the true target a negligible probability of being chosen.
Intuitively, this null object can be interpreted as recognizing a failure to refer to anything.
Second, we add an explicit noise model at every level of recursion.
That is, we assume every agent has a probability $\epsilon$ of choosing a random element of the support, ensuring a fixed non-zero floor on the likelihood of each element that is constant across levels of recursion.
Formally this corresponds to a mixture distribution, e.g. 
$$L_0^{\epsilon}(o|u,\phi) = \epsilon \cdot P_{unif}(o) + (1-\epsilon) \cdot L_0(o|u,\phi)$$
$$S_1^{\epsilon}(u|o,\phi) = \epsilon \cdot P_{unif}(u) + (1-\epsilon) \cdot S_1(u|o,\phi)$$

\subsection{Marginalizing over $\phi_k$}
Another major theoretical question arises about exactly how speaker and listener agents ought to marginalize over their uncertainty about $\phi_k$ when selecting actions (Eq.~\ref{eq:marginalized}). 
In our formulation, the expectation is taken over the entire \emph{utility} each agent is using to act, i.e. if the speaker and listener utilities are defined to be 
$$
\begin{array}{rcl}
U_L(o;u, \phi_k) & = & w_L \cdot \log S_1(u|o, \phi_k)\\
U_S(u;o, \phi_k) & = & w_S \cdot \log L_1(o|u, \phi_k) - w_C \cdot c(u) \\
\end{array}
$$
then the expectation is taken as follow:
$$
\begin{array}{rcl}
L(o|u) & \propto & \exp\left\{\int P(\phi_k |D_k)\cdot U_L(u; o, \phi_k) \, d \phi_k\right\}\\
S(u|o) & \propto & \exp\left\{\int P(\phi_k | D_k) \cdot U_S(u; o, \phi_k) \, d \phi_k\right\} \\
\end{array}
$$
We may interpret this formulation as each agent choosing an action proportional to its expected utility across different possible values of $\phi_k$, weighted by the agent's current posterior beliefs about the value their partner is using.

This formulation contrasts with the one suggested by \citeA{bergen_pragmatic_2016}, which assumes the expectation takes places at a single level of recursion, say the $L_1$, as above, and then derives the other agent's behavior by reasoning directly about this marginalized distribution, e.g.
$$
\begin{array}{rcl}
S_{alt1}(u|o) & \propto & \exp\left\{w_S \cdot \log L(o|u) - w_C \cdot c(u)\right\} \\
\end{array}
$$
where $L(o|u)$ is defined as above.
This may be interpreted as an assumption on the part of the speaker that the listener is already accounting for their own uncertainty, and best responding to such a listener.
Isolating lexical uncertainty over $\phi$ to a single level of recursion is a natural formulation for one-shot pragmatic phenomena, where additional layers of recursion can build on top of this marginal distribution to derive implicatures.
However, the interpretation is messier for the multi-agent setting, since it (1) induces an asymmetry where one agent considers the other's uncertainty but not vice versa, and (2) requires the speaker to use their own current posterior beliefs to reason about the listener's marginalization.

A third variant we considered is to place the expectation outside the listener distribution but inside the speaker's informativity term.
$$
\begin{array}{rcl}
L_{avg} & = & \int P(\phi_k | D_k) L(o|u, \phi_k) d\phi_k \\
S_{alt2}(u|o) & \propto & \exp\left\{w_S \cdot \log L_{avg}(o|u) - w_C \cdot c(u)\right\} \\
\end{array}
$$
The interpretation of this variant is that the speaker first derives a distribution representing how the listener would respond \emph{on expectation} and then computes their surprisal relative to this composite listener.
While this variant is able to derive the desired phenomena, it can be shown that it induces an unintuitive initial bias under a uniform lexical prior, since the logarithm cannot distribute over the integral in the normalization constant. 
This bias was most apparent in the case of context-sensitivity (Simulation 3).
Mathematically, the difference between these possibilities is whether the speaker's uncertainty about $\phi_k$ goes inside the renormalization of $L(o|u)$ (as in $S_{alt1}$), outside the renormalization but inside the logarithm (as in $S_{alt2}$), or over the entire utility (as in our chosen formulation).

\subsection{Alternative lexical representations}

In this section, we re-consider two specific choices we made about how to represent lexical meanings.

First, for simplicity and consistency with earlier models of Bayesian word learning, we adopted a traditional truth-conditional representation of lexical meaning throughout the paper. 
Each word in the lexicon is mapped to a single `concept' to , e.g. $w_1 = `blue square'$, where this utterance is true of objects the fall in the given concept, and false otherwise. 
The inference problem over lexicons therefore requires searching over this discrete space of word-concept mappings. 
However, it is important to emphasize that our model is entirely consistent with alternative lexical representations.

For example, for some settings, a \emph{continuous, real-valued} representation may be preferred, or a higher-dimensional vector representation.
Rather than assigning each word a discrete concept in the lexicon, we may simply assign each word-object pair $(w_i,o_j)$ a scalar meaning representing the extent to which word $w_i$ applies to object $o_j$, such that $\phi$ is a real-valued matrix:
$$
\phi = \begin{bmatrix}
\phi^{(11)} & \phi^{(12)} & \cdots & \phi^{(1i)} \\
\phi^{(21)} & \phi^{(22)} & \cdots & \phi^{(2j)} \\
\vdots & \vdots &\ddots & \vdots \\
\phi^{(j1)} & \phi^{(j2)} & \cdots & \phi^{(ij)} 
\end{bmatrix}
$$
and $\mathcal{L}_\phi(w_i, o_j) = \phi^{(ij)}$. 
In this case, rather than discrete categorical priors over meanings, we may place Gaussian priors over the entries of this matrix:
\begin{align}
\Theta^{(ij)} & \sim \mathcal{N}(0,1)\nonumber \\
\phi^{(ij)} & \sim \mathcal{N}(\Theta^{(ij)} | 1)\nonumber
\end{align}
We have previously achieved similar results using this alternative lexical representations in earlier versions of this manuscript \cite{hawkins_convention-formation_2017,hawkins2020generalizing}.

Second, we introduced a simple disjunctive operation allowing the speaker agent to derive longer utterances from primitive utterances.  
While disjunction was the simplest such function for the purposes of our simulations, we also considered conjunctive operator, defined as a $t$-norm.
\begin{align}
\mathcal{L}(u_1+u_2, o) & = \min\{\mathcal{L}(u_1, o), \mathcal{L}(u_2, o)\} \nonumber\\
\end{align}
While we were also able to derive the basic reduction phenomenon using the conjunction operation \cite{hawkins_convention-formation_2017,hawkins2020generalizing}, this result depended on whether or not we included a `null' object (see \emph{Handling degenerate lexicons} above). 
Specifically, the conjunction operation only allows for reduction in the \emph{absence} of a null object, where the listener is assumed to choose randomly between the objects when an utterance evaluates to false for all of them.
Speakers will initially prefer the longer utterance $u_1+u_2$ because it has a higher probably of cancelling out and leading to random guessing for lexicons where either $u_1$ or $u_2$ or both are false of the target.
In other words, when both $u_1$ and $u_2$ are true of the target, the listener will choose it with perfect accuracy, and in the other three cases they will choose it with 50\% accuracy.
Once a null object is introduced, however, these same lexicons will lead to only \epsilon accuracy (since the listener will choose the null object instead of the target when the utterance is false), making the conjunction riskier than simply choosing one of the component utterances.


 \begin{figure*}
\centering
    \includegraphics[scale=.9]{arbitrariness_grid.pdf}
  \caption{Coordination success (simulation 1.1) across a range of parameter values. Columns represent memory discount factors $\beta$, rows represent optimality parameters $w_S = w_L$. Communicative success is achieved under a wide range of settings, but convergence is limited in some regimes. At high values of $\beta$, with no ability to discount prior evidence, accuracy asymptotes quickly below perfect coordination; at low $\alpha$, inferences are weaker and agent actions are noisier, limiting the ability to converge; finally, at low values of $\beta$, when prior evidence is forgotten too quickly, convergence interacts with $\alpha$: when $\alpha$ is too high, the latest evidence may overwhelm all prior evidence, preventing the accumulation of shared history. The agent noise model is set to $\epsilon = 0.01$ in all simulations.}
  \label{fig:arbitrariness_grid}
\end{figure*}

 \begin{figure*}
\centering
    \includegraphics[scale=.7]{conjunction_grid.pdf}
  \caption{Speaker efficiency (simulation 1.2) across a range of parameter values representing different weights on informativity and cost. Rows represent agent optimality $w_S = w_L$, columns represent costs $w_C$, and different memory discount factors $\beta$ shown in different colors. Agents converge on more efficient ad hoc conventions for a wide regime of parameters. Broadly, when utterance cost is more heavily weighted relative to informativity, the speaker will not produce longer utterances even at the beginning of the interaction; when informativity is more heavily weighted, the speaker continues to prefer longer utterances despite their cost. Reduction is found at the critical point between this tradeoff. The exception is at low values of $w_C$, where reduction is found even at higher optimality simply due to compression when re-normalizing the speaker distribution.}
  \label{fig:conjunction_grid}
\end{figure*}

 \begin{figure*}
\centering
    \includegraphics[scale=.9]{exp2-acc-grid_cleaned.pdf}
  \caption{Raw empirical accuracy distributions for context-sensitivity experiment. Each row represents how the accuracies of different games shift across the four quarters of the task for a given condition. Dotted vertical line represents chance accuracy (0.25), solid vertical line represents pre-registered convergence threshold (0.75).}
  \label{fig:full_accuracy_grid}
\end{figure*}

 \begin{figure*}
\centering
    \includegraphics[scale=.8]{reduction_grid_search.pdf}
  \caption{Speaker efficiency across partners (simulation 3.2) for a range of parameter values. Rows represent speaker optimality $w_S$, columns represent cost weight $w_c$.}
  \label{fig:partnerspecificity_grid}
\end{figure*}
\end{document}  

