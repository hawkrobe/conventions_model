\documentclass[11pt, floatsintext]{apa6}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[outdir=./]{epstopdf}
%\DeclareGraphicsExtensions{.eps}
\usepackage{caption}
\captionsetup{font=footnotesize}

\usepackage{mathtools}
\usepackage{enumerate}
\usepackage{textcomp}
\usepackage{lingmacros}
\usepackage[draft]{hyperref}
\usepackage{apacite}
\usepackage{listings}
\usepackage{multirow}
\usepackage{stfloats}
\usepackage{todonotes}
\usepackage{svg}
\usepackage{booktabs}
\usepackage{stmaryrd}

\newcommand*{\bluesquare}[0]{%
\mathord{
    %\raisebox{-.6\baselineskip}{%
        \includegraphics[
        height=.6em,
        width=.6em,
        keepaspectratio,
        ]{square.pdf}%
    }
}

\newcommand*{\orangecircle}[0]{%
\mathord{
%\mathchoice{
        \includegraphics[
        height=.6em,
        width=.6em,
        keepaspectratio,
        ]{circle.pdf}%
    }%
}

\synctex=1
\usepackage{soul}

\newcommand{\den}[1]{\ensuremath{\llbracket #1 \rrbracket}}

\newcommand{\KL}[2]{\ensuremath{D_{KL}({#1}\, \| \, {#2})}}
\newcommand{\E}[2]{\ensuremath{\mathbb{E}_{#1}\left [#2 \right]}}

\newenvironment{figurehere}
	{\def\@captype{figure}}
	{}

\usepackage{lipsum}
%\pagenumbering{gobble}
%\usepackage{apacite}

\linespread{1}


\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}
\graphicspath{{./figures/}}
 
 \definecolor{Green}{RGB}{10,200,100}
  \definecolor{Red}{RGB}{200,100,50}
\newcommand{\ks}[1]{\textcolor{Red}{[ks: #1]}}  
\newcommand{\rdh}[1]{\textcolor{Red}{[rdh: #1]}}  
\newcommand{\ndg}[1]{\textcolor{Green}{[ndg: #1]}}  


\makeatother

\title{From partners to populations: \\[.1em] A hierarchical Bayesian account of coordination and convention}
\shorttitle{Conventions}
\leftheader{Hawkins et al.}
\author{Robert D. Hawkins$^{*1}$, Michael Franke$^2$, Michael C. Frank$^3$, \\ Adele E. Goldberg$^1$,  Kenny Smith$^4$, Thomas L. Griffiths$^{1,5}$, Noah D. Goodman$^{3,6}$}

\affiliation{$^1$Department of Psychology, Princeton University, $^2$Institute for Cognitive Science, University of Osnabr\"uck, \\$^3$Department of Psychology, Stanford University, $^4$Centre for Language Evolution, University of Edinburgh, $^5$Department of Computer Science, Princeton University, $^6$Department of Computer Science, Stanford University }

\abstract{Languages are powerful solutions to coordination problems: they provide stable, shared expectations about how the words we say correspond to the beliefs and intentions in our heads. 
Yet language use in a variable and non-stationary social environment requires linguistic representations to be flexible: old words acquire new \emph{ad hoc} or partner-specific meanings on the fly. 
In this paper, we introduce a hierarchical Bayesian theory of convention formation that aims to reconcile the long-standing tension between these two basic observations.
More specifically, we argue that the central computational problem of communication is not simply transmission, as in classical formulations, but \emph{learning} and \emph{adaptation} over multiple timescales.
Under our account, rapid learning within dyadic interactions allows for coordination on partner-specific common ground, while social conventions are stable priors that have been abstracted away from interactions with multiple partners.
We present new empirical data alongside simulations showing how our model provides a cognitive foundation for explaining several phenomena that have posed a challenge for previous accounts: (1) the convergence to more efficient referring expressions across repeated interaction with the same partner, (2) the gradual transfer of partner-specific common ground to novel partners, and (3) the influence of communicative context on which conventions eventually form.
%Finally, we discuss several broader consequences of our framework, grounding community-level social conventions in basic individual-level learning mechanisms,  suggests new perspectives on continual language learning beyond development. 
}

\keywords{Keywords TBD}

\authornote{This report is based in part on work presented at the 39th, 40th, and 42nd Conferences of the Cognitive Science Society \cite{hawkins_convention-formation_2017,hawkins_emerging_abstractions_2018,hawkins2020generalizing}. Materials and code for reproducing all model simulations, behavioral experiments, and analyses are open and available online at \href{https://github.com/hawkrobe/conventions_model}{https://github.com/hawkrobe/conventions\_model}.\\
$^*$Correspondence should be addressed to Robert  Hawkins, e-mail: rdhawkins@princeton.edu}

\begin{document}
\maketitle

\input{Introduction}

\section{Convention formation as\\ Hierarchical Bayesian inference}

\input{ModelOverview}

\section{Phenomenon \#1: \\ \emph{Ad hoc} conventions become more efficient}

\input{Reduction}

\section{Phenomenon \#2: \\ Conventions gradually generalize \\to new partners in a social network}

\input{Generalization}

\section{Phenomenon \#3: \\ Conventions are shaped by communicative context}

\input{ContextSensitivity}

\section{General Discussion}

\input{Conclusion}

%\section{\bf Acknowledgments}
\small

\bibliography{ref}
\bibliographystyle{apacite-no-initials}

\renewcommand{\thefigure}{A\arabic{figure}}
\renewcommand{\thetable}{A\arabic{table}}
\setcounter{table}{0}
\setcounter{figure}{0}





\begin{table*}[th!]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{}                                   & \textbf{Parameter}                                              & \multicolumn{1}{l}{\textbf{Example parameter settings}}                 \\ \midrule
\multirow{11}{*}{\textbf{Partner design}}    & \multirow{3}{*}{What feedback is provided?}                & - no feedback at all                                                  \\
                                            &                                                                 & - only correct/incorrect                                                   \\
                                            &                                                                 & - real-time responses from partner                                         \\ \cmidrule(l){2-3} 
                                            & \multirow{3}{*}{Are you playing with the same partner?}         & - same partner for whole game                                              \\
                                            &                                                                 & - swap out partners every round                                            \\
                                            &                                                                 & - swap after $k$ rounds                                                    \\ \cmidrule(l){2-3} 
                                            & \multirow{3}{*}{What do you know about your partner?}         & - anonymous stranger                                              \\
                                            &                                                                 & - stranger with perceptual information                                            \\
                                            &                                                                 & - close friend                                                    \\ \cmidrule(l){2-3}                                             
                                            & \multirow{2}{*}{How consistent are roles across repetitions?}   & - consistent director/matcher                                              \\
                                            &                                                                 & - alternate roles each round                                               \\ \midrule
\multirow{7}{*}{\textbf{Stimulus design}}   & \multirow{2}{*}{How familiar are targets?}                      & - very familiar: colors, household objects                                 \\
                                            &                                                                 & - not at all familiar: tangrams, novel line drawings                       \\ \cmidrule(l){2-3} 
                                            & \multirow{2}{*}{How complex are targets?}                       & - very complex: busy visual scenes, clips of music                         \\
                                            &                                                                 & - not at all complex: geometric drawings                                   \\ \cmidrule(l){2-3} 
                                            & \multirow{3}{*}{How consistent are targets across repetitions?} & - exact same image of object                                               \\
                                            &                                                                 & - different pose/view of same object                                       \\
                                            &                                                                 & - different objects from same neighborhood                                 \\ \midrule
\multirow{5}{*}{\textbf{Context design}}    & \multirow{2}{*}{How similar are distractors to the target?}     & - very similar: same basic-level category                                  \\
                                            &                                                                 & - not at all similar: other categories                                     \\ \cmidrule(l){2-3} 
                                            & What is the size of context?                                    & - between 2 and 21                                                         \\ \cmidrule(l){2-3} 
                                            & \multirow{2}{*}{How consistent is context across repetitions?}  & - exact same context each round                                            \\
                                            &                                                                 & - randomized context (sometimes far, sometimes close)                      \\ \midrule
\multirow{3}{*}{\textbf{Repetition design}} & How many repetitions per target?                                & - between 3 and 100                                                        \\ \cmidrule(l){2-3} 
                                            & \multirow{2}{*}{What is spacing between repetitions?}           & - block structure                                                          \\
                                            &                                                                 & - sequential structure with interspersed contexts                          \\ \midrule
\textbf{Modality design}                    & What medium is used for communication?                          & \begin{tabular}[c]{@{}l@{}}- text\\ - audio\\ - gesture\\ - drawing\end{tabular} \\ \bottomrule
\end{tabular}%
}
\caption{\normalfont{Proposed parameterization for repeated reference games, each of which theoretically impacts the formation of conventions.}}
\label{table:parameters}
\end{table*}

\normalsize

\section*{Appendix A: Details of RSA model}

Our setting poses several technical challenges for the Rational Speech Act (RSA) framework.
In this Appendix, we describe these challenges in more detail and justify our choices.

\subsection{Handling degenerate lexicons}

First, when we allow the full space of possible lexicons $\phi$, we must confront degenerate lexicons where an utterance $u$ is literally false of every object in context, i.e. where $\mathcal{L}_\phi(o, u) = 0$ for all $o\in \mathcal{C}$. 
In this case, the normalizing constant in Eq.~\ref{eq:RSA} is zero, and the literal listener distribution is not well-defined.
A similar problem may arise when no utterance in the speaker's repertoire is true of the target, in which case the $S_1$ distribution is not well-defined.

Several solutions to this problem were outlined by \citeA{bergen_pragmatic_2016}.
One of these solutions is to use a `softer' semantics in the literal listener, where a Boolean value of false does not strictly rule out an object but instead assigns a very low numerical score, e.g. 
$$\mathcal{L}_\phi(o,u) = \left\{ \begin{array} {rl} 1 & \textrm{if }o \in \phi(u) \\ \epsilon & \textrm{o.w.} \end{array}\right.$$
Whenever there is at least one $o\in\mathcal{C}$ where $u$ is true, this formulation assigns negligible listener probability to objects where $u$ is false, but ensures that the normalization constant to is non-zero even when $u$ is false for all objects.

While this solution suffices for one-shot pragmatics under lexical uncertainty, where $\epsilon$ may be calibrated to be appropriately large, it runs into several technical complications in an iterated setting.
First, due to numerical overflow at sufficiently high values of $w_L$ and $w_S$ at later iterations, elements may drop entirely out of the support at higher levels of recursion (e.g. $L_1$), leading the normalization constant to return to zero. 
Second, this `soft' semantics creates unexpected and unintuitive consequences at the level of the pragmatic speaker. 
After renormalization in $L_0$, an utterance $u$ that fails to refer to any object in context is also by definition equally \emph{successful} for all objects (i.e. evaluating to $\epsilon$ for every object), leading to a uniform selection distribution.
Consequently, $S_1$ may in some cases prefer utterances that are literally false of the target just as much as utterances which are true.

Instead of injecting $\epsilon$ into the lexical meaning, we ensure that the normalization constant is well-defined by adapting another method suggested by \citeA{bergen_pragmatic_2016}.
First, we add a `null' object to every context so that, even if a particular utterance is false of every real object in context, it will still apply to the null object, assigning the true target a negligible probability of being chosen.
Intuitively, this null object can be interpreted as recognizing that the referring expression has a referent but it is not in context.
Second, we add an explicit noise model at every level of recursion.
That is, we assume every agent has a probability $\epsilon$ of choosing a random element of their support, ensuring a fixed non-zero floor on the likelihood of each element that is constant across levels of recursion.
Formally this corresponds to a mixture distribution, e.g. 
$$L_0^{\epsilon}(o|u,\phi) = \epsilon \cdot P_{unif}(o) + (1-\epsilon) \cdot L_0(o|u,\phi)$$
$$S_1^{\epsilon}(u|o,\phi) = \epsilon \cdot P_{unif}(u) + (1-\epsilon) \cdot S_1(u|o,\phi)$$

\subsection{Marginalizing over $\phi_k$}
Another theoretical question arises about exactly how speaker and listener agents ought to marginalize over their uncertainty about $\phi_k$ when selecting actions (Eq.~\ref{eq:marginalized}). 
In our formulation, the expectation is naturally taken over the entire \emph{utility} each agent is using to act, i.e. if the speaker and listener utilities are defined to be 
$$
\begin{array}{rcl}
U_L(o;u, \phi_k) & = &  \log S_1(u|o, \phi_k)\\
U_S(u;o, \phi_k) & = &  (1-w_C)\log L_0(o|u, \phi_k) - w_C \cdot c(u) \\
\end{array}
$$
then the expectation is taken as follow:
$$
\begin{array}{rcl}
L(o|u) & \propto & \exp\left\{w_L\int P_L(\phi_k |D_k)\cdot U_L(u; o, \phi_k) \, d \phi_k\right\}\\
S(u|o) & \propto & \exp\left\{w_S\int P_S(\phi_k | D_k) \cdot U_S(u; o, \phi_k) \, d \phi_k\right\} \\
\end{array}
$$
This formulation may be interpreted as each agent choosing an action proportional to its expected utility across different possible values of $\phi_k$, weighted by the agent's current posterior beliefs about the lexicon their partner is using.

This formulation contrasts with the one suggested by \citeA{bergen_pragmatic_2016}, which assumes the expectation takes places at a single level of recursion, say the $L_1$, as above, and then derives the other agent's behavior by having them reason directly about this marginalized distribution, e.g.
$$
\begin{array}{rcl}
U_{alt1}(u;o) & = & (1-w_C) \cdot \log L(o|u) - w_C \cdot c(u)\\
S_{alt1}(u|o) & \propto & \exp\left\{w_S \cdot U_{alt1}(u;o)\right\} \\
\end{array}
$$
where $L(o|u)$ is defined as above.
This formulation may be interpreted as an assumption on the part of the speaker that the listener is already accounting for their own uncertainty, and best responding to such a listener.
Isolating lexical uncertainty over $\phi$ to a single level of recursion is a natural formulation for one-shot pragmatic phenomena, where additional layers of recursion can build on top of this marginal distribution to derive implicatures.
However, the interpretation is messier for the multi-agent setting, since it (1) induces an asymmetry where one agent considers the other's uncertainty but not vice versa, and (2) requires the speaker to use their own current posterior beliefs to reason about the listener's marginalization.

A third possible variant is to place the expectation outside the listener distribution but inside the speaker's informativity term, i.e..
$$
\begin{array}{rcl}
L_{avg} & = & \int P(\phi_k | D_k)\cdot L_0(o|u, \phi_k) d\phi_k \\
U_{alt2}(u;o) & = & (1-w_C) \cdot \log L_{avg}(o|u) - w_C \cdot c(u)\\
S_{alt2}(u|o) & \propto & \exp\left\{w_S \cdot U_{alt2}(u;o)\right\} \\
\end{array}
$$
The interpretation here is that the speaker first derives a distribution representing how a listener would respond \emph{on expectation} and then computes their surprisal relative to this composite listener.
While this variant is in principle able to derive the desired phenomena, it can be shown that it induces an unintuitive initial bias under a uniform lexical prior, since the logarithm cannot distribute over the integral in the normalization constant. 
This bias is most apparent in the case of context-sensitivity (Simulation 3).

Mathematically, the difference between these alternatives is whether the speaker's uncertainty about $\phi_k$ goes inside the renormalization of $L(o|u)$ (as in $S_{alt1}$), outside the renormalization but inside the logarithm (as in $S_{alt2}$), or over the entire utility (as in our chosen formulation).
While other formulations are conceivable, we argue that marginalizing over the entire utility is not only the most natural but also normatively correct under Bayesian decision theory. 
When an agent is uncertain about some aspect of the decision problem, rational choice requires the agent to optimize expected utility marginalizing over subjective uncertainty, as in our formulation. 

\subsection{Appendix B: Alternative lexical representations}

In this section, we re-consider two specific choices we made about how to represent lexical meanings.

First, for simplicity and consistency with earlier models of Bayesian word learning, we adopted a traditional truth-conditional representation of lexical meaning throughout the paper. 
Each word in the lexicon is mapped to a single `concept' to , e.g. $w_1 = `blue square'$, where this utterance is true of objects the fall in the given concept, and false otherwise. 
The inference problem over lexicons therefore requires searching over this discrete space of word-concept mappings. 
However, it is important to emphasize that our model is entirely consistent with alternative lexical representations.

For example, for some settings, a \emph{continuous, real-valued} representation may be preferred, or a higher-dimensional vector representation.
Rather than assigning each word a discrete concept in the lexicon, we may simply assign each word-object pair $(w_i,o_j)$ a scalar meaning representing the extent to which word $w_i$ applies to object $o_j$, such that $\phi$ is a real-valued matrix:
$$
\phi = \begin{bmatrix}
\phi^{(11)} & \phi^{(12)} & \cdots & \phi^{(1i)} \\
\phi^{(21)} & \phi^{(22)} & \cdots & \phi^{(2j)} \\
\vdots & \vdots &\ddots & \vdots \\
\phi^{(j1)} & \phi^{(j2)} & \cdots & \phi^{(ij)} 
\end{bmatrix}
$$
and $\mathcal{L}_\phi(w_i, o_j) = \phi^{(ij)}$. 
In this case, rather than discrete categorical priors over meanings, we may place Gaussian priors over the entries of this matrix:
\begin{align}
\Theta^{(ij)} & \sim \mathcal{N}(0,1)\nonumber \\
\phi^{(ij)} & \sim \mathcal{N}(\Theta^{(ij)} | 1)\nonumber
\end{align}
We have previously achieved similar results using this alternative lexical representations in earlier iteration of this manuscript \cite{hawkins_convention-formation_2017,hawkins2020generalizing}, although deriving predictions required variational inference techniques rather than Markov Chain Monte Carlo. 
Such optimization-based inference techniques may also provide the most promising path for extending our adaptive model to larger language models, including neural networks that operate over continuous spaces of image pixels and natural language embeddings \cite{hawkins2019continual}.

%Second, we used a conjunction operation to derive the semantics of longer utterances from primitive utterances, which captures the intuitive behavior of a speaker who proposes multiple possible descriptions, or ways of seeing the object.
%However, it is reasonable to consider alternative ways of interpreting a multi-word utterance, including a disjunctive `max' operation:
%\begin{align}
%\mathcal{L}(u_1,u_2, o) & = \max\{\mathcal{L}(u_1, o), \mathcal{L}(u_2, o)\} \nonumber
%\end{align}
%We are able to derive the same reduction phenomenon using this alternative operation, 
%Specifically, the alternative `min' operation only allows for reduction when degenerate lexicons are handled by having the listener choose randomly between the objects when an utterance evaluates to false for all of them.
%Speakers initially prefer the longer utterance $u_1+u_2$ because it has a higher probability of failing to refer to anything and leading to random guessing for lexicons where either $u_1$ or $u_2$ or both are false of the target.
%In other words, the reduction phenomenon emerges for the conjunctive semantics only as a consequence of strategically designing utterances that fail to refer to the target, which we find an unlikely explanation for human speaker behavior.
%When degenerate lexicons are handled by introducing a null object, however, these same lexicons lead to poor accuracy (since the listener will choose the null object instead of the target when the utterance is false), reflecting the riskiness of producing a conjunction that fails to refer to the target. 


 \begin{figure*}
\centering
    \includegraphics[scale=1.2]{arbitrariness_grid.pdf}
  \caption{Coordination success (simulation 1.1) across a range of parameter values. Columns represent memory discount parameter $\beta$, and rows represent agent soft-max temperatures, where we set $\alpha_S=\alpha_L$. Communicative success is achieved under a wide range of settings, but convergence is limited in some regimes. For example, at high values of $\beta$, with no ability to discount prior evidence, accuracy rises quickly but asymptotes below perfect coordination; at low $\alpha$, inferences are slightly weaker and agent actions are noisier, slowing convergence; finally, at low values of $\beta$, when prior evidence is forgotten too quickly, convergence interacts with $\alpha$: the latest evidence may overwhelm all prior evidence, preventing the accumulation of shared history. The agent noise model is set to $\epsilon = 0.01$ in all simulations.}
  \label{fig:arbitrariness_grid}
\end{figure*}

 \begin{figure*}
\centering
    \includegraphics[scale=1.2]{conjuction_grid.pdf}
  \caption{Speaker efficiency (simulation 1.2) across a range of parameter values representing different weights on informativity and cost. Rows represent agent optimality $w_S = w_L$, columns represent costs $w_C$, and different memory discount factors $\beta$ shown in different colors. Agents converge on more efficient ad hoc conventions for a wide regime of parameters. When utterance production cost $w_C$ is more heavily weighted relative to informativity, the speaker is less likely to produce longer utterances, even at the beginning of the interaction; when optimality $w_S, w_L$ is higher, and the speaker maximizes utility, we observe faster reduction and more categorical behavior. Note that as $\alpha\rightarrow\infty$, utterances only become shorter at $w_C=0$ in the absence of forgetting. In this case, the shorter utterances approach the exact same utility as the longer utterance, and the speaker reaches equilibrium simply sampling among them at random (i.e. choosing the longer utterance with 1/3 probability and each of the shorter utterances with 1/3 probability).}
  \label{fig:conjunction_grid}
\end{figure*}


 \begin{figure*}
\centering
    \includegraphics[scale=.8]{grid_all_models.pdf}
  \caption{Speaker efficiency simulations for \textbf{P2} across a larger parameter regime. We examine the behavior of complete-pooling, no-pooling, and partial-pooling models, where rows represent agent optimality $\alpha_S = \alpha_L$, columns represent cost weight $w_c$, and colors represent memory discount parameter $\beta$.}
  \label{fig:partnerspecificity_grid}
\end{figure*}


\begin{figure*}
\includegraphics[scale=1.2]{./figures/param_grid_qualitative_cleaned.pdf}
\caption{Qualitative predictions of our three models for \textbf{P2}. Across a wide range of parameter values, only the hierarchical model consistently produces both qualitative phenomena of interest: reversion to the prior at partner boundaries (i.e. a ``jump'') and gradual generalization across partners (i.e. a ``drop''). Approximately $N=10$ simulations used to compute $t$-statistic in each cell. Cells marked with black boxes are significantly different from a null effect of 0 change, $p<0.005$.}
\label{fig:generalization_modelcomparison}
\end{figure*}


 \begin{figure*}
\centering
    \includegraphics[scale=.9]{exp2-acc-grid_cleaned.pdf}
  \caption{Raw empirical accuracy distributions for context-sensitivity experiment. Each row represents how the accuracies of different games shift across the four quarters of the task for a given condition. Dotted vertical line represents chance accuracy (0.25), solid vertical line represents pre-registered convergence threshold (0.75).}
  \label{fig:full_accuracy_grid}
\end{figure*}


 \begin{figure*}
\centering
    \includegraphics[scale=.9]{mixtureOfTerms.pdf}
  \caption{Empirical mixtures of terms reported by participants in \textbf{P3}. While the modal lexicon in the coarse condition contained 0 specific terms and 4 more general terms (32\% of participants) and the modal lexicon in the mixture and fine conditions contained 8 specific terms and 0 more general terms (42\% and 38\% of participants, respectively), many participants reported a mixture of abstract and specific terms.}
  \label{fig:mixtureOfTerms}
\end{figure*}

\end{document}  

